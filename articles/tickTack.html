<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>tickTack • tickTack</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="tickTack">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">tickTack</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.0.9</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item"><a class="nav-link" href="../articles/tickTack.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>tickTack</h1>
            
      

      <div class="d-none name"><code>tickTack.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="overview">Overview<a class="anchor" aria-label="anchor" href="#overview"></a>
</h2>
<p>tickTack requires in input a CNAqc object with attributes cna,
mutations and metadata. The main input for the tool are: * the read
counts from somatic mutations such as single-nucleotide variants (SNVs)
in the mutation attribute; * allele-specific copy number segments (CNAs)
for clonal segments must be encoded in the cna attribute; * a tumor
purity estimate in the metadata.</p>
<p>The tool uses chromosome coordinates to map mutations to segments.
The conversion of relative to absolute genome coordinates requires to
fix a reference genome build; supported reference is GRCh38/hg17 that is
also supported in CNAqc.</p>
<p>tickTack can be used to time the genomic segmnents affected by a Copy
Number event, identifying the main clocks at which the event can be
associated.</p>
</div>
<div class="section level2">
<h2 id="the-model">The model<a class="anchor" aria-label="anchor" href="#the-model"></a>
</h2>
<p>The following concepts are used to infer copy number timing.</p>
<div class="section level3">
<h3 id="vaf-peaks">VAF peaks<a class="anchor" aria-label="anchor" href="#vaf-peaks"></a>
</h3>
<p>The point mutations that are present on the duplicated region are
duplicated in copy with the segment. Therefore we can use the proportion
of mutations happede before and after the Copy Number event
distinguishing between mutations in single copy and double copies.</p>
<p><img src="timing_problem.png" alt="Overview timing problem" width="650"><br></p>
<p>Therefore, for a single segment the value of the clock associated
with the Copy Number event is obtained as a transformation from the
proportions of mutations in single and double copy. The following
quantities need to be considered:</p>
<p><img src="Mutations_single_double_copy_draw_process.png" alt="Overview timing problem" width="650"><br></p>
<p>In the case of a trisomy without LOH, we can consider the fact that,
before
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>,
1 chromosome will accumulate mutations that will duplicate, while the
other will accumulate mutations that will remain in single copy. On the
other hand, after
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>,
both chromosomes will accumulate mutations which will remain in single
copy. Therefore one can write the system:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mrow><mo stretchy="true" form="prefix">{</mo><mtable><mtr><mtd columnalign="left" style="text-align: left"><msub><mi>N</mi><mn>2</mn></msub><mo>=</mo><mi>ρ</mi><mi>τ</mi><msub><mi>N</mi><mn>1</mn></msub><mo>=</mo><mi>ρ</mi><mi>τ</mi><mo>+</mo><mn>3</mn><mi>ρ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>τ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr></mtable></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align}
    \begin{cases}
        N_2 = \rho \tau  
        N_1 = \rho \tau + 3\rho(1 - \tau) \nonumber % Use \nonumber to prevent numbering for a specific line
    \end{cases}
\end{align}</annotation></semantics></math></p>
<p>Using the first one to obtain
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ρ</mi><annotation encoding="application/x-tex">\rho</annotation></semantics></math>
and inserting into the second one, the solution for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
becomes:</p>
<p><span class="math display">$$\begin{equation}
    N_1 = N_2 + \frac{3N_2}{\tau}(1-\tau) \hspace{2mm} \rightarrow
\hspace{2mm} N_1 + 2N_2 = \frac{3N_2}{\tau} \hspace{2mm} \rightarrow
\hspace{2mm} \tau = \frac{3N_2}{N_1 + 2N_2}
\end{equation}$$</span></p>
<p>The case of the CNLOH and of the segment doubling can be treated
together. In fact, in the first case, before
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
the mutations that will duplicate accumulate on a single chromosome and
after
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
the mutations that will remain in a single copy accumulate on two
chromosomes. The system therefore becomes:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mrow><mo stretchy="true" form="prefix">{</mo><mtable><mtr><mtd columnalign="left" style="text-align: left"><msub><mi>N</mi><mn>2</mn></msub><mo>=</mo><mi>ρ</mi><mi>τ</mi><msub><mi>N</mi><mn>1</mn></msub><mo>=</mo><mn>2</mn><mi>ρ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>τ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr></mtable></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align}
    \begin{cases}
        N_2 = \rho \tau  
        N_1 = 2\rho(1 - \tau) \nonumber 
    \end{cases}
\end{align}</annotation></semantics></math></p>
<p>A very similar things happens in the case of the 2:2, with the only
difference that the number of chromosomes accumulating a certain type of
mutation will be double, both after and before
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>.
Hence, the system becomes:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mrow><mo stretchy="true" form="prefix">{</mo><mtable><mtr><mtd columnalign="left" style="text-align: left"><msub><mi>N</mi><mn>2</mn></msub><mo>=</mo><mn>2</mn><mi>ρ</mi><mi>τ</mi><msub><mi>N</mi><mn>1</mn></msub><mo>=</mo><mn>4</mn><mi>ρ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>τ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr></mtable></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align}
    \begin{cases}
        N_2 = 2\rho \tau  
        N_1 = 4\rho(1 - \tau) \nonumber 
    \end{cases}
\end{align}</annotation></semantics></math></p>
<p>Therefore, the two system can be solved similarly (you can simply
drop a factor of 2 in the second case). The solution for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
easily becomes:</p>
<p><span class="math display">$$\begin{equation}
    N_1 = \frac{2N_2(1-\tau)}{\tau} \hspace{2mm} \rightarrow
\hspace{2mm} \tau(N_1 + 2N_2) = 2N_2 \hspace{2mm} \rightarrow
\hspace{2mm} \tau = \frac{2N_2}{2N_2 + N_1}
\end{equation}$$</span></p>
</div>
<div class="section level3">
<h3 id="clonal-cnas">Clonal CNAs<a class="anchor" aria-label="anchor" href="#clonal-cnas"></a>
</h3>
<p>Consider:</p>
<ul>
<li>mutations sitting on a segment
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>A</mi><mo>:</mo><mi>n</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">nA:nB</annotation></semantics></math>;</li>
<li>tumour purity
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math>;</li>
<li>a healthy diploid normal;</li>
</ul>
<p>Since the proportion of all reads from the tumour is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>n</mi><mi>A</mi></msub><mo>+</mo><msub><mi>n</mi><mi>B</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\pi(n_A+n_B)</annotation></semantics></math>,
and from the normal is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>π</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">2(1-\pi)</annotation></semantics></math>.
Then, muations present in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
copies of the tumour genome should peak at VAF value
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>m</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>c</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac displaystyle="true"><mrow><mi>m</mi><mi>π</mi><mi>c</mi></mrow><mrow><mn>2</mn><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>π</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>π</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>n</mi><mi>A</mi></msub><mo>+</mo><msub><mi>n</mi><mi>B</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mspace width="0.167em"></mspace><mi>.</mi></mrow><annotation encoding="application/x-tex">
v_m(c) = \dfrac{m \pi c}{
2 (1 - \pi) + \pi (n_A+n_B)
} \, .
</annotation></semantics></math></p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://caravagnalab.github.io/tickTack/">tickTack</a></span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load template data</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu">tickTack</span><span class="fu">::</span><span class="va"><a href="../reference/pcawg_example.html">pcawg_example</a></span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tibble.tidyverse.org/" class="external-link">tibble</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'dplyr'</span></span>
<span><span class="co">#&gt; The following objects are masked from 'package:stats':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     filter, lag</span></span>
<span><span class="co">#&gt; The following objects are masked from 'package:base':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     intersect, setdiff, setequal, union</span></span>
<span></span>
<span><span class="va">data_reduced</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>mutations <span class="op">=</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span> <span class="va">data</span><span class="op">$</span><span class="va">mutations</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">chr</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"chr"</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, </span>
<span>                     cna <span class="op">=</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span> <span class="va">data</span><span class="op">$</span><span class="va">cna</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="va">chr</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"chr"</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                     metadata <span class="op">=</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>purity <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">metadata</span><span class="op">$</span><span class="va">purity</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">data_reduced</span> <span class="op">&lt;-</span> <span class="fu">tickTack</span><span class="fu">::</span><span class="fu"><a href="../reference/fit_h.html">fit_h</a></span><span class="op">(</span><span class="va">data_reduced</span>, max_attempts<span class="op">=</span><span class="fl">2</span>, INIT<span class="op">=</span><span class="cn">TRUE</span>, tolerance <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1</span></span>
<span><span class="co">#&gt; [1] 2</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">2</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 3</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">3</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 4</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">5</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 6</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">6</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 7</span></span>
<span><span class="co">#&gt; [1] 8</span></span>
<span><span class="co">#&gt; [1] 9</span></span>
<span><span class="co">#&gt; [1] 10</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">10</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 11</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">11</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 12</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">12</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 13</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">13</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 14</span></span>
<span><span class="co">#&gt; [1] 15</span></span>
<span><span class="co">#&gt; [1] 16</span></span>
<span><span class="co">#&gt; [1] 17</span></span>
<span><span class="co">#&gt; [1] 18</span></span>
<span><span class="co">#&gt; [1] 19</span></span>
<span><span class="co">#&gt; [1] 20</span></span>
<span><span class="co">#&gt; [1] 21</span></span>
<span><span class="co">#&gt; [1] 22</span></span>
<span><span class="co">#&gt; [1] 23</span></span>
<span><span class="co">#&gt; [1] 24</span></span>
<span><span class="co">#&gt; [1] 25</span></span>
<span><span class="co">#&gt; [1] 26</span></span>
<span><span class="co">#&gt; [1] 27</span></span>
<span><span class="co">#&gt; [1] 28</span></span>
<span><span class="co">#&gt; [1] 29</span></span>
<span><span class="co">#&gt; [1] 30</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">30</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 31</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">31</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 32</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">32</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 33</span></span>
<span><span class="co">#&gt; [1] 34</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">34</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 35</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">35</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 36</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">36</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 37</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">37</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 38</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">38</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 39</span></span>
<span><span class="co">#&gt; [1] 40</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">40</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 41</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">41</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 42</span></span>
<span><span class="co">#&gt; [1] 43</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">43</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 44</span></span>
<span><span class="co">#&gt; [1] 45</span></span>
<span><span class="co">#&gt; [1] 46</span></span>
<span><span class="co">#&gt; [1] 47</span></span>
<span><span class="co">#&gt; [1] 48</span></span>
<span><span class="co">#&gt; [1] 49</span></span>
<span><span class="co">#&gt; [1] 50</span></span>
<span><span class="co">#&gt; [1] 51</span></span>
<span><span class="co">#&gt; [1] 52</span></span>
<span><span class="co">#&gt; [1] 53</span></span>
<span><span class="co">#&gt; [1] 54</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">54</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 55</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">55</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 56</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">56</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 57</span></span>
<span><span class="co">#&gt; [1] 58</span></span>
<span><span class="co">#&gt; [1] 59</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">59</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 60</span></span>
<span><span class="co">#&gt; [1] 61</span></span>
<span><span class="co">#&gt; [1] 62</span></span>
<span><span class="co">#&gt; [1] 63</span></span>
<span><span class="co">#&gt; [1] 64</span></span>
<span><span class="co">#&gt; [1] 65</span></span>
<span><span class="co">#&gt; [1] 66</span></span>
<span><span class="co">#&gt; [1] 67</span></span>
<span><span class="co">#&gt; [1] 68</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">68</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 69</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">69</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 70</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">70</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 71</span></span>
<span><span class="co">#&gt; [1] 72</span></span>
<span><span class="co">#&gt; [1] 73</span></span>
<span><span class="co">#&gt; [1] 74</span></span>
<span><span class="co">#&gt; [1] 75</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">75</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 76</span></span>
<span><span class="co">#&gt; [1] 77</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">77</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 78</span></span>
<span><span class="co">#&gt; [1] 79</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">79</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 80</span></span>
<span><span class="co">#&gt; [1] 81</span></span>
<span><span class="co">#&gt; [1] 82</span></span>
<span><span class="co">#&gt; [1] 83</span></span>
<span><span class="co">#&gt; [1] 84</span></span>
<span><span class="co">#&gt; [1] 85</span></span>
<span><span class="co">#&gt; [1] 86</span></span>
<span><span class="co">#&gt; [1] 87</span></span>
<span><span class="co">#&gt; [1] 88</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">88</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 89</span></span>
<span><span class="co">#&gt; [1] 90</span></span>
<span><span class="co">#&gt; [1] 91</span></span>
<span><span class="co">#&gt; [1] 92</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">92</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 93</span></span>
<span><span class="co">#&gt; [1] 94</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">94</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 95</span></span>
<span><span class="co">#&gt; [1] 96</span></span>
<span><span class="co">#&gt; [1] 97</span></span>
<span><span class="co">#&gt; [1] 98</span></span>
<span><span class="co">#&gt; [1] 99</span></span>
<span><span class="co">#&gt; [1] 100</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">100</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 101</span></span>
<span><span class="co">#&gt; [1] 102</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">102</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 103</span></span>
<span><span class="co">#&gt; [1] 104</span></span>
<span><span class="co">#&gt; [1] 105</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">105</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 106</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">106</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 107</span></span>
<span><span class="co">#&gt; [1] 108</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">108</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 109</span></span>
<span><span class="co">#&gt; [1] 110</span></span>
<span><span class="co">#&gt; [1] 111</span></span>
<span><span class="co">#&gt; [1] 112</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">112</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 113</span></span>
<span><span class="co">#&gt; [1] 114</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">114</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 115</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">115</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 116</span></span>
<span><span class="co">#&gt; [1] 117</span></span>
<span><span class="co">#&gt; [1] 118</span></span>
<span><span class="co">#&gt; [1] 119</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">119</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; [1] 120</span></span>
<span><span class="co">#&gt; [1] 121</span></span>
<span><span class="co">#&gt; [1] 122</span></span>
<span><span class="co">#&gt; [1] 123</span></span>
<span><span class="co">#&gt; [1] 124</span></span>
<span><span class="co">#&gt; [1] 125</span></span>
<span><span class="co">#&gt; [1] 126</span></span>
<span><span class="co">#&gt; <span style="color: #00BBBB;">ℹ</span> Adding segment with index <span style="color: #0000BB;">126</span> to segments included in the inference.</span></span>
<span><span class="co">#&gt; init_taus from clustering  0.717296623368948</span></span>
<span><span class="co">#&gt; Attempt 1 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.00214 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 21.4 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -10825.886             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -10814.777             0.501            1.000 </span></span>
<span><span class="co">#&gt;      3       -10808.363             0.334            0.001   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  5.8 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;       [,1]</span></span>
<span><span class="co">#&gt;  [1,]    1</span></span>
<span><span class="co">#&gt;  [2,]    1</span></span>
<span><span class="co">#&gt;  [3,]    1</span></span>
<span><span class="co">#&gt;  [4,]    1</span></span>
<span><span class="co">#&gt;  [5,]    1</span></span>
<span><span class="co">#&gt;  [6,]    1</span></span>
<span><span class="co">#&gt;  [7,]    1</span></span>
<span><span class="co">#&gt;  [8,]    1</span></span>
<span><span class="co">#&gt;  [9,]    1</span></span>
<span><span class="co">#&gt; [10,]    1</span></span>
<span><span class="co">#&gt; [11,]    1</span></span>
<span><span class="co">#&gt; [12,]    1</span></span>
<span><span class="co">#&gt; [13,]    1</span></span>
<span><span class="co">#&gt; [14,]    1</span></span>
<span><span class="co">#&gt; [15,]    1</span></span>
<span><span class="co">#&gt; [16,]    1</span></span>
<span><span class="co">#&gt; [17,]    1</span></span>
<span><span class="co">#&gt; [18,]    1</span></span>
<span><span class="co">#&gt; [19,]    1</span></span>
<span><span class="co">#&gt; [20,]    1</span></span>
<span><span class="co">#&gt; [21,]    1</span></span>
<span><span class="co">#&gt; [22,]    1</span></span>
<span><span class="co">#&gt; [23,]    1</span></span>
<span><span class="co">#&gt; [24,]    1</span></span>
<span><span class="co">#&gt; [25,]    1</span></span>
<span><span class="co">#&gt; [26,]    1</span></span>
<span><span class="co">#&gt; [27,]    1</span></span>
<span><span class="co">#&gt; [28,]    1</span></span>
<span><span class="co">#&gt; [29,]    1</span></span>
<span><span class="co">#&gt; [30,]    1</span></span>
<span><span class="co">#&gt; [31,]    1</span></span>
<span><span class="co">#&gt; [32,]    1</span></span>
<span><span class="co">#&gt; [33,]    1</span></span>
<span><span class="co">#&gt; [34,]    1</span></span>
<span><span class="co">#&gt; [35,]    1</span></span>
<span><span class="co">#&gt; [36,]    1</span></span>
<span><span class="co">#&gt; [37,]    1</span></span>
<span><span class="co">#&gt; [38,]    1</span></span>
<span><span class="co">#&gt; [39,]    1</span></span>
<span><span class="co">#&gt; [40,]    1</span></span>
<span><span class="co">#&gt; [41,]    1</span></span>
<span><span class="co">#&gt; [42,]    1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.7172966</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -10808.4</span></span>
<span><span class="co">#&gt; Attempt 2 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.00213 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 21.3 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -10871.395             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -10843.020             0.501            1.000 </span></span>
<span><span class="co">#&gt;      3       -10820.577             0.335            0.003   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  5.5 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;       [,1]</span></span>
<span><span class="co">#&gt;  [1,]    1</span></span>
<span><span class="co">#&gt;  [2,]    1</span></span>
<span><span class="co">#&gt;  [3,]    1</span></span>
<span><span class="co">#&gt;  [4,]    1</span></span>
<span><span class="co">#&gt;  [5,]    1</span></span>
<span><span class="co">#&gt;  [6,]    1</span></span>
<span><span class="co">#&gt;  [7,]    1</span></span>
<span><span class="co">#&gt;  [8,]    1</span></span>
<span><span class="co">#&gt;  [9,]    1</span></span>
<span><span class="co">#&gt; [10,]    1</span></span>
<span><span class="co">#&gt; [11,]    1</span></span>
<span><span class="co">#&gt; [12,]    1</span></span>
<span><span class="co">#&gt; [13,]    1</span></span>
<span><span class="co">#&gt; [14,]    1</span></span>
<span><span class="co">#&gt; [15,]    1</span></span>
<span><span class="co">#&gt; [16,]    1</span></span>
<span><span class="co">#&gt; [17,]    1</span></span>
<span><span class="co">#&gt; [18,]    1</span></span>
<span><span class="co">#&gt; [19,]    1</span></span>
<span><span class="co">#&gt; [20,]    1</span></span>
<span><span class="co">#&gt; [21,]    1</span></span>
<span><span class="co">#&gt; [22,]    1</span></span>
<span><span class="co">#&gt; [23,]    1</span></span>
<span><span class="co">#&gt; [24,]    1</span></span>
<span><span class="co">#&gt; [25,]    1</span></span>
<span><span class="co">#&gt; [26,]    1</span></span>
<span><span class="co">#&gt; [27,]    1</span></span>
<span><span class="co">#&gt; [28,]    1</span></span>
<span><span class="co">#&gt; [29,]    1</span></span>
<span><span class="co">#&gt; [30,]    1</span></span>
<span><span class="co">#&gt; [31,]    1</span></span>
<span><span class="co">#&gt; [32,]    1</span></span>
<span><span class="co">#&gt; [33,]    1</span></span>
<span><span class="co">#&gt; [34,]    1</span></span>
<span><span class="co">#&gt; [35,]    1</span></span>
<span><span class="co">#&gt; [36,]    1</span></span>
<span><span class="co">#&gt; [37,]    1</span></span>
<span><span class="co">#&gt; [38,]    1</span></span>
<span><span class="co">#&gt; [39,]    1</span></span>
<span><span class="co">#&gt; [40,]    1</span></span>
<span><span class="co">#&gt; [41,]    1</span></span>
<span><span class="co">#&gt; [42,]    1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.5895146</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -10820.6</span></span>
<span><span class="co">#&gt; [1] "output_files /tmp/RtmpYyUiwz/timing_mixed_simple-diagnostic-202411270930-1-00cac1.csv\n"</span></span>
<span><span class="co">#&gt; init_taus from clustering  0.782061595984112 init_taus from clustering  0.507845095347554</span></span>
<span><span class="co">#&gt; Attempt 1 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.003755 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 37.55 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -10962.993             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -10865.013             0.505            1.000 </span></span>
<span><span class="co">#&gt;      3       -10859.971             0.336            0.009   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  18.6 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;              [,1]         [,2]</span></span>
<span><span class="co">#&gt;  [1,] 0.972999145 0.0270008551</span></span>
<span><span class="co">#&gt;  [2,] 0.969321695 0.0306783054</span></span>
<span><span class="co">#&gt;  [3,] 0.981764906 0.0182350940</span></span>
<span><span class="co">#&gt;  [4,] 0.999616900 0.0003831003</span></span>
<span><span class="co">#&gt;  [5,] 0.902747743 0.0972522571</span></span>
<span><span class="co">#&gt;  [6,] 0.989109653 0.0108903471</span></span>
<span><span class="co">#&gt;  [7,] 0.999881617 0.0001183833</span></span>
<span><span class="co">#&gt;  [8,] 0.996135532 0.0038644680</span></span>
<span><span class="co">#&gt;  [9,] 0.953537574 0.0464624263</span></span>
<span><span class="co">#&gt; [10,] 0.927032342 0.0729676581</span></span>
<span><span class="co">#&gt; [11,] 0.964453722 0.0355462785</span></span>
<span><span class="co">#&gt; [12,] 0.987812071 0.0121879288</span></span>
<span><span class="co">#&gt; [13,] 0.813929280 0.1860707203</span></span>
<span><span class="co">#&gt; [14,] 0.927071758 0.0729282423</span></span>
<span><span class="co">#&gt; [15,] 0.204312715 0.7956872853</span></span>
<span><span class="co">#&gt; [16,] 0.998115707 0.0018842928</span></span>
<span><span class="co">#&gt; [17,] 0.974913460 0.0250865396</span></span>
<span><span class="co">#&gt; [18,] 0.990825863 0.0091741372</span></span>
<span><span class="co">#&gt; [19,] 0.997507809 0.0024921912</span></span>
<span><span class="co">#&gt; [20,] 0.941312900 0.0586871003</span></span>
<span><span class="co">#&gt; [21,] 0.654761345 0.3452386546</span></span>
<span><span class="co">#&gt; [22,] 0.997252182 0.0027478181</span></span>
<span><span class="co">#&gt; [23,] 0.996135532 0.0038644680</span></span>
<span><span class="co">#&gt; [24,] 0.007795247 0.9922047533</span></span>
<span><span class="co">#&gt; [25,] 0.999288695 0.0007113054</span></span>
<span><span class="co">#&gt; [26,] 0.949709200 0.0502907997</span></span>
<span><span class="co">#&gt; [27,] 0.139418013 0.8605819870</span></span>
<span><span class="co">#&gt; [28,] 0.006482878 0.9935171217</span></span>
<span><span class="co">#&gt; [29,] 0.023104783 0.9768952174</span></span>
<span><span class="co">#&gt; [30,] 0.996135532 0.0038644680</span></span>
<span><span class="co">#&gt; [31,] 0.955731756 0.0442682445</span></span>
<span><span class="co">#&gt; [32,] 0.294303978 0.7056960216</span></span>
<span><span class="co">#&gt; [33,] 0.968632302 0.0313676979</span></span>
<span><span class="co">#&gt; [34,] 0.955731756 0.0442682445</span></span>
<span><span class="co">#&gt; [35,] 0.296588739 0.7034112608</span></span>
<span><span class="co">#&gt; [36,] 0.083789627 0.9162103729</span></span>
<span><span class="co">#&gt; [37,] 0.654761345 0.3452386546</span></span>
<span><span class="co">#&gt; [38,] 0.975677209 0.0243227914</span></span>
<span><span class="co">#&gt; [39,] 0.955731756 0.0442682445</span></span>
<span><span class="co">#&gt; [40,] 0.955731756 0.0442682445</span></span>
<span><span class="co">#&gt; [41,] 0.941312900 0.0586871003</span></span>
<span><span class="co">#&gt; [42,] 0.002484797 0.9975152026</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.7820616 0.5078451</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 0.5 0.5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -10860</span></span>
<span><span class="co">#&gt; Attempt 2 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.00376 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 37.6 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -11158.401             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -10928.649             0.511            1.000 </span></span>
<span><span class="co">#&gt;      3       -10894.860             0.341            0.021   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  8.1 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;              [,1]         [,2]</span></span>
<span><span class="co">#&gt;  [1,] 0.972999145 0.0270008551</span></span>
<span><span class="co">#&gt;  [2,] 0.969321695 0.0306783054</span></span>
<span><span class="co">#&gt;  [3,] 0.981764906 0.0182350940</span></span>
<span><span class="co">#&gt;  [4,] 0.999616900 0.0003831003</span></span>
<span><span class="co">#&gt;  [5,] 0.902747743 0.0972522571</span></span>
<span><span class="co">#&gt;  [6,] 0.989109653 0.0108903471</span></span>
<span><span class="co">#&gt;  [7,] 0.999881617 0.0001183833</span></span>
<span><span class="co">#&gt;  [8,] 0.996135532 0.0038644680</span></span>
<span><span class="co">#&gt;  [9,] 0.953537574 0.0464624263</span></span>
<span><span class="co">#&gt; [10,] 0.927032342 0.0729676581</span></span>
<span><span class="co">#&gt; [11,] 0.964453722 0.0355462785</span></span>
<span><span class="co">#&gt; [12,] 0.987812071 0.0121879288</span></span>
<span><span class="co">#&gt; [13,] 0.813929280 0.1860707203</span></span>
<span><span class="co">#&gt; [14,] 0.927071758 0.0729282423</span></span>
<span><span class="co">#&gt; [15,] 0.204312715 0.7956872853</span></span>
<span><span class="co">#&gt; [16,] 0.998115707 0.0018842928</span></span>
<span><span class="co">#&gt; [17,] 0.974913460 0.0250865396</span></span>
<span><span class="co">#&gt; [18,] 0.990825863 0.0091741372</span></span>
<span><span class="co">#&gt; [19,] 0.997507809 0.0024921912</span></span>
<span><span class="co">#&gt; [20,] 0.941312900 0.0586871003</span></span>
<span><span class="co">#&gt; [21,] 0.654761345 0.3452386546</span></span>
<span><span class="co">#&gt; [22,] 0.997252182 0.0027478181</span></span>
<span><span class="co">#&gt; [23,] 0.996135532 0.0038644680</span></span>
<span><span class="co">#&gt; [24,] 0.007795247 0.9922047533</span></span>
<span><span class="co">#&gt; [25,] 0.999288695 0.0007113054</span></span>
<span><span class="co">#&gt; [26,] 0.949709200 0.0502907997</span></span>
<span><span class="co">#&gt; [27,] 0.139418013 0.8605819870</span></span>
<span><span class="co">#&gt; [28,] 0.006482878 0.9935171217</span></span>
<span><span class="co">#&gt; [29,] 0.023104783 0.9768952174</span></span>
<span><span class="co">#&gt; [30,] 0.996135532 0.0038644680</span></span>
<span><span class="co">#&gt; [31,] 0.955731756 0.0442682445</span></span>
<span><span class="co">#&gt; [32,] 0.294303978 0.7056960216</span></span>
<span><span class="co">#&gt; [33,] 0.968632302 0.0313676979</span></span>
<span><span class="co">#&gt; [34,] 0.955731756 0.0442682445</span></span>
<span><span class="co">#&gt; [35,] 0.296588739 0.7034112608</span></span>
<span><span class="co">#&gt; [36,] 0.083789627 0.9162103729</span></span>
<span><span class="co">#&gt; [37,] 0.654761345 0.3452386546</span></span>
<span><span class="co">#&gt; [38,] 0.975677209 0.0243227914</span></span>
<span><span class="co">#&gt; [39,] 0.955731756 0.0442682445</span></span>
<span><span class="co">#&gt; [40,] 0.955731756 0.0442682445</span></span>
<span><span class="co">#&gt; [41,] 0.941312900 0.0586871003</span></span>
<span><span class="co">#&gt; [42,] 0.002484797 0.9975152026</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.5170100 0.4303675</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 0.5 0.5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -10894.9</span></span>
<span><span class="co">#&gt; [1] "output_files /tmp/RtmpYyUiwz/timing_mixed_simple-diagnostic-202411270930-1-952a4f.csv\n"</span></span>
<span><span class="co">#&gt; init_taus from clustering  0.821674291112562 init_taus from clustering  0.486384833469723 init_taus from clustering  0.711213122092432</span></span>
<span><span class="co">#&gt; Attempt 1 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.005593 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 55.93 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -10968.281             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -10927.013             0.502            1.000 </span></span>
<span><span class="co">#&gt;      3       -10908.342             0.335            0.004   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  26.3 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;               [,1]         [,2]         [,3]</span></span>
<span><span class="co">#&gt;  [1,] 0.9837855558 0.0019220734 0.0142923707</span></span>
<span><span class="co">#&gt;  [2,] 0.9746643773 0.0030765663 0.0222590564</span></span>
<span><span class="co">#&gt;  [3,] 0.9987392242 0.0002078260 0.0010529498</span></span>
<span><span class="co">#&gt;  [4,] 0.8147338765 0.0111092638 0.1741568597</span></span>
<span><span class="co">#&gt;  [5,] 0.0009377637 0.0002858036 0.9987764327</span></span>
<span><span class="co">#&gt;  [6,] 0.3136083667 0.0186116669 0.6677799664</span></span>
<span><span class="co">#&gt;  [7,] 0.7682562017 0.0129740879 0.2187697104</span></span>
<span><span class="co">#&gt;  [8,] 0.9394967790 0.0045762383 0.0559269827</span></span>
<span><span class="co">#&gt;  [9,] 0.0537214233 0.0071355929 0.9391429837</span></span>
<span><span class="co">#&gt; [10,] 0.8537874708 0.0239132093 0.1222993199</span></span>
<span><span class="co">#&gt; [11,] 0.0916486479 0.0102414561 0.8981098959</span></span>
<span><span class="co">#&gt; [12,] 0.2919337278 0.0182505699 0.6898157024</span></span>
<span><span class="co">#&gt; [13,] 0.0189241829 0.0073323872 0.9737434299</span></span>
<span><span class="co">#&gt; [14,] 0.0117126835 0.0021765845 0.9861107320</span></span>
<span><span class="co">#&gt; [15,] 0.1140115366 0.4330905905 0.4528978729</span></span>
<span><span class="co">#&gt; [16,] 0.5702225256 0.0182256392 0.4115518352</span></span>
<span><span class="co">#&gt; [17,] 0.1516224684 0.0137744401 0.8346030915</span></span>
<span><span class="co">#&gt; [18,] 0.9876410591 0.0011508346 0.0112081063</span></span>
<span><span class="co">#&gt; [19,] 0.5405575817 0.0186561155 0.4407863028</span></span>
<span><span class="co">#&gt; [20,] 0.0282347812 0.0044164319 0.9673487870</span></span>
<span><span class="co">#&gt; [21,] 0.0722079817 0.0533503351 0.8744416832</span></span>
<span><span class="co">#&gt; [22,] 0.5292600782 0.0187954734 0.4519444484</span></span>
<span><span class="co">#&gt; [23,] 0.9394967790 0.0045762383 0.0559269827</span></span>
<span><span class="co">#&gt; [24,] 0.0003175796 0.9991054263 0.0005769941</span></span>
<span><span class="co">#&gt; [25,] 0.8417150401 0.0099007815 0.1483841784</span></span>
<span><span class="co">#&gt; [26,] 0.0442279386 0.0061994829 0.9495725785</span></span>
<span><span class="co">#&gt; [27,] 0.0993679692 0.5474747779 0.3531572529</span></span>
<span><span class="co">#&gt; [28,] 0.0001519567 0.9996332692 0.0002147742</span></span>
<span><span class="co">#&gt; [29,] 0.0375810610 0.8587992681 0.1036196710</span></span>
<span><span class="co">#&gt; [30,] 0.9394967790 0.0045762383 0.0559269827</span></span>
<span><span class="co">#&gt; [31,] 0.9359077605 0.0086714188 0.0554208206</span></span>
<span><span class="co">#&gt; [32,] 0.1221529668 0.3118042785 0.5660427547</span></span>
<span><span class="co">#&gt; [33,] 0.9728497049 0.0033143242 0.0238359708</span></span>
<span><span class="co">#&gt; [34,] 0.9359077605 0.0086714188 0.0554208206</span></span>
<span><span class="co">#&gt; [35,] 0.1927310749 0.5500351778 0.2572337473</span></span>
<span><span class="co">#&gt; [36,] 0.0779092616 0.6725230317 0.2495677068</span></span>
<span><span class="co">#&gt; [37,] 0.0722079817 0.0533503351 0.8744416832</span></span>
<span><span class="co">#&gt; [38,] 0.9896323243 0.0012210181 0.0091466576</span></span>
<span><span class="co">#&gt; [39,] 0.9359077605 0.0086714188 0.0554208206</span></span>
<span><span class="co">#&gt; [40,] 0.9359077605 0.0086714188 0.0554208206</span></span>
<span><span class="co">#&gt; [41,] 0.0282347812 0.0044164319 0.9673487870</span></span>
<span><span class="co">#&gt; [42,] 0.0006030386 0.9981530619 0.0012438995</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.8216743 0.4863848 0.7112131</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 0.3333333 0.3333333 0.3333333</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -10908.3</span></span>
<span><span class="co">#&gt; Attempt 2 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.005618 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 56.18 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -11055.865             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -10940.572             0.505            1.000 </span></span>
<span><span class="co">#&gt;      3       -10913.694             0.338            0.011   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  26.3 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;               [,1]         [,2]         [,3]</span></span>
<span><span class="co">#&gt;  [1,] 0.9837855558 0.0019220734 0.0142923707</span></span>
<span><span class="co">#&gt;  [2,] 0.9746643773 0.0030765663 0.0222590564</span></span>
<span><span class="co">#&gt;  [3,] 0.9987392242 0.0002078260 0.0010529498</span></span>
<span><span class="co">#&gt;  [4,] 0.8147338765 0.0111092638 0.1741568597</span></span>
<span><span class="co">#&gt;  [5,] 0.0009377637 0.0002858036 0.9987764327</span></span>
<span><span class="co">#&gt;  [6,] 0.3136083667 0.0186116669 0.6677799664</span></span>
<span><span class="co">#&gt;  [7,] 0.7682562017 0.0129740879 0.2187697104</span></span>
<span><span class="co">#&gt;  [8,] 0.9394967790 0.0045762383 0.0559269827</span></span>
<span><span class="co">#&gt;  [9,] 0.0537214233 0.0071355929 0.9391429837</span></span>
<span><span class="co">#&gt; [10,] 0.8537874708 0.0239132093 0.1222993199</span></span>
<span><span class="co">#&gt; [11,] 0.0916486479 0.0102414561 0.8981098959</span></span>
<span><span class="co">#&gt; [12,] 0.2919337278 0.0182505699 0.6898157024</span></span>
<span><span class="co">#&gt; [13,] 0.0189241829 0.0073323872 0.9737434299</span></span>
<span><span class="co">#&gt; [14,] 0.0117126835 0.0021765845 0.9861107320</span></span>
<span><span class="co">#&gt; [15,] 0.1140115366 0.4330905905 0.4528978729</span></span>
<span><span class="co">#&gt; [16,] 0.5702225256 0.0182256392 0.4115518352</span></span>
<span><span class="co">#&gt; [17,] 0.1516224684 0.0137744401 0.8346030915</span></span>
<span><span class="co">#&gt; [18,] 0.9876410591 0.0011508346 0.0112081063</span></span>
<span><span class="co">#&gt; [19,] 0.5405575817 0.0186561155 0.4407863028</span></span>
<span><span class="co">#&gt; [20,] 0.0282347812 0.0044164319 0.9673487870</span></span>
<span><span class="co">#&gt; [21,] 0.0722079817 0.0533503351 0.8744416832</span></span>
<span><span class="co">#&gt; [22,] 0.5292600782 0.0187954734 0.4519444484</span></span>
<span><span class="co">#&gt; [23,] 0.9394967790 0.0045762383 0.0559269827</span></span>
<span><span class="co">#&gt; [24,] 0.0003175796 0.9991054263 0.0005769941</span></span>
<span><span class="co">#&gt; [25,] 0.8417150401 0.0099007815 0.1483841784</span></span>
<span><span class="co">#&gt; [26,] 0.0442279386 0.0061994829 0.9495725785</span></span>
<span><span class="co">#&gt; [27,] 0.0993679692 0.5474747779 0.3531572529</span></span>
<span><span class="co">#&gt; [28,] 0.0001519567 0.9996332692 0.0002147742</span></span>
<span><span class="co">#&gt; [29,] 0.0375810610 0.8587992681 0.1036196710</span></span>
<span><span class="co">#&gt; [30,] 0.9394967790 0.0045762383 0.0559269827</span></span>
<span><span class="co">#&gt; [31,] 0.9359077605 0.0086714188 0.0554208206</span></span>
<span><span class="co">#&gt; [32,] 0.1221529668 0.3118042785 0.5660427547</span></span>
<span><span class="co">#&gt; [33,] 0.9728497049 0.0033143242 0.0238359708</span></span>
<span><span class="co">#&gt; [34,] 0.9359077605 0.0086714188 0.0554208206</span></span>
<span><span class="co">#&gt; [35,] 0.1927310749 0.5500351778 0.2572337473</span></span>
<span><span class="co">#&gt; [36,] 0.0779092616 0.6725230317 0.2495677068</span></span>
<span><span class="co">#&gt; [37,] 0.0722079817 0.0533503351 0.8744416832</span></span>
<span><span class="co">#&gt; [38,] 0.9896323243 0.0012210181 0.0091466576</span></span>
<span><span class="co">#&gt; [39,] 0.9359077605 0.0086714188 0.0554208206</span></span>
<span><span class="co">#&gt; [40,] 0.9359077605 0.0086714188 0.0554208206</span></span>
<span><span class="co">#&gt; [41,] 0.0282347812 0.0044164319 0.9673487870</span></span>
<span><span class="co">#&gt; [42,] 0.0006030386 0.9981530619 0.0012438995</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.7540726 0.4742881 0.8674985</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 0.3333333 0.3333333 0.3333333</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -10913.7</span></span>
<span><span class="co">#&gt; [1] "output_files /tmp/RtmpYyUiwz/timing_mixed_simple-diagnostic-202411270930-1-869567.csv\n"</span></span>
<span><span class="co">#&gt; init_taus from clustering  0.833266358182747 init_taus from clustering  0.000641472811587056 init_taus from clustering  0.542989332490939 init_taus from clustering  0.733629632496324</span></span>
<span><span class="co">#&gt; Attempt 1 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.007138 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 71.38 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -11151.518             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -10962.230             0.509            1.000 </span></span>
<span><span class="co">#&gt;      3       -10941.921             0.340            0.017   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  34.3 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;               [,1]         [,2]         [,3]         [,4]</span></span>
<span><span class="co">#&gt;  [1,] 0.9984004359 1.173267e-04 0.0002406451 0.0012415923</span></span>
<span><span class="co">#&gt;  [2,] 0.9933766205 1.904071e-04 0.0008182809 0.0056146914</span></span>
<span><span class="co">#&gt;  [3,] 0.9910951413 1.949085e-04 0.0009105352 0.0077994150</span></span>
<span><span class="co">#&gt;  [4,] 0.5534770204 2.037070e-03 0.0202454525 0.4242404574</span></span>
<span><span class="co">#&gt;  [5,] 0.0254301811 8.035428e-04 0.0123078562 0.9614584199</span></span>
<span><span class="co">#&gt;  [6,] 0.0776064507 9.079886e-04 0.0102520617 0.9112334991</span></span>
<span><span class="co">#&gt;  [7,] 0.4843977085 2.078632e-03 0.0210949069 0.4924287524</span></span>
<span><span class="co">#&gt;  [8,] 0.7877221806 1.462008e-03 0.0132739794 0.1975418321</span></span>
<span><span class="co">#&gt;  [9,] 0.0002216401 1.022658e-04 0.0001343432 0.9995417509</span></span>
<span><span class="co">#&gt; [10,] 0.8631822744 3.485800e-03 0.0224261923 0.1109057330</span></span>
<span><span class="co">#&gt; [11,] 0.0021449549 1.341394e-04 0.0005888147 0.9971320910</span></span>
<span><span class="co">#&gt; [12,] 0.0668612842 8.237421e-04 0.0092788935 0.9230360803</span></span>
<span><span class="co">#&gt; [13,] 0.0715909250 3.015456e-03 0.0619641350 0.8634294838</span></span>
<span><span class="co">#&gt; [14,] 0.0108101469 3.546296e-04 0.0042344535 0.9846007700</span></span>
<span><span class="co">#&gt; [15,] 0.0479272686 7.339603e-03 0.7988423691 0.1458907596</span></span>
<span><span class="co">#&gt; [16,] 0.2582285537 1.790023e-03 0.0193994922 0.7205819308</span></span>
<span><span class="co">#&gt; [17,] 0.0139956356 2.992467e-04 0.0028210909 0.9828840268</span></span>
<span><span class="co">#&gt; [18,] 0.9174735098 7.873177e-04 0.0063813311 0.0753578413</span></span>
<span><span class="co">#&gt; [19,] 0.2317978105 1.706749e-03 0.0186406636 0.7478547771</span></span>
<span><span class="co">#&gt; [20,] 0.0036415856 1.752623e-04 0.0012703801 0.9949127720</span></span>
<span><span class="co">#&gt; [21,] 0.1103148479 6.991522e-03 0.1998397863 0.6828538438</span></span>
<span><span class="co">#&gt; [22,] 0.2221577042 1.673234e-03 0.0183261850 0.7578428765</span></span>
<span><span class="co">#&gt; [23,] 0.7877221806 1.462008e-03 0.0132739794 0.1975418321</span></span>
<span><span class="co">#&gt; [24,] 0.0277986593 1.494299e-02 0.9032587618 0.0539995903</span></span>
<span><span class="co">#&gt; [25,] 0.5973096571 1.981387e-03 0.0194190810 0.3812898744</span></span>
<span><span class="co">#&gt; [26,] 0.0008597157 1.149213e-04 0.0003260866 0.9986992764</span></span>
<span><span class="co">#&gt; [27,] 0.0277799331 5.009366e-03 0.8892361213 0.0779745798</span></span>
<span><span class="co">#&gt; [28,] 0.0260730638 1.366797e-02 0.9093202772 0.0509386883</span></span>
<span><span class="co">#&gt; [29,] 0.0001214352 1.060253e-04 0.9996225484 0.0001499911</span></span>
<span><span class="co">#&gt; [30,] 0.7877221806 1.462008e-03 0.0132739794 0.1975418321</span></span>
<span><span class="co">#&gt; [31,] 0.9575967584 8.450343e-04 0.0056378365 0.0359203708</span></span>
<span><span class="co">#&gt; [32,] 0.0738045277 9.352504e-03 0.6663920182 0.2504509498</span></span>
<span><span class="co">#&gt; [33,] 0.9921090594 2.098650e-04 0.0009696709 0.0067114047</span></span>
<span><span class="co">#&gt; [34,] 0.9575967584 8.450343e-04 0.0056378365 0.0359203708</span></span>
<span><span class="co">#&gt; [35,] 0.0001002408 9.996988e-01 0.0001006214 0.0001003223</span></span>
<span><span class="co">#&gt; [36,] 0.0114357248 2.483766e-03 0.9564322241 0.0296482850</span></span>
<span><span class="co">#&gt; [37,] 0.1103148479 6.991522e-03 0.1998397863 0.6828538438</span></span>
<span><span class="co">#&gt; [38,] 0.9996992700 9.997078e-05 0.0001000486 0.0001007107</span></span>
<span><span class="co">#&gt; [39,] 0.9575967584 8.450343e-04 0.0056378365 0.0359203708</span></span>
<span><span class="co">#&gt; [40,] 0.9575967584 8.450343e-04 0.0056378365 0.0359203708</span></span>
<span><span class="co">#&gt; [41,] 0.0036415856 1.752623e-04 0.0012703801 0.9949127720</span></span>
<span><span class="co">#&gt; [42,] 0.0196935294 9.388817e-03 0.9315671947 0.0393504589</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.8332663582 0.0006414728 0.5429893325 0.7336296325</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 0.25 0.25 0.25 0.25</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -10941.9</span></span>
<span><span class="co">#&gt; Attempt 2 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.007062 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 70.62 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -11166.861             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -11006.753             0.507            1.000 </span></span>
<span><span class="co">#&gt;      3       -10976.026             0.339            0.015   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  34.2 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;               [,1]         [,2]         [,3]         [,4]</span></span>
<span><span class="co">#&gt;  [1,] 0.9984004359 1.173267e-04 0.0002406451 0.0012415923</span></span>
<span><span class="co">#&gt;  [2,] 0.9933766205 1.904071e-04 0.0008182809 0.0056146914</span></span>
<span><span class="co">#&gt;  [3,] 0.9910951413 1.949085e-04 0.0009105352 0.0077994150</span></span>
<span><span class="co">#&gt;  [4,] 0.5534770204 2.037070e-03 0.0202454525 0.4242404574</span></span>
<span><span class="co">#&gt;  [5,] 0.0254301811 8.035428e-04 0.0123078562 0.9614584199</span></span>
<span><span class="co">#&gt;  [6,] 0.0776064507 9.079886e-04 0.0102520617 0.9112334991</span></span>
<span><span class="co">#&gt;  [7,] 0.4843977085 2.078632e-03 0.0210949069 0.4924287524</span></span>
<span><span class="co">#&gt;  [8,] 0.7877221806 1.462008e-03 0.0132739794 0.1975418321</span></span>
<span><span class="co">#&gt;  [9,] 0.0002216401 1.022658e-04 0.0001343432 0.9995417509</span></span>
<span><span class="co">#&gt; [10,] 0.8631822744 3.485800e-03 0.0224261923 0.1109057330</span></span>
<span><span class="co">#&gt; [11,] 0.0021449549 1.341394e-04 0.0005888147 0.9971320910</span></span>
<span><span class="co">#&gt; [12,] 0.0668612842 8.237421e-04 0.0092788935 0.9230360803</span></span>
<span><span class="co">#&gt; [13,] 0.0715909250 3.015456e-03 0.0619641350 0.8634294838</span></span>
<span><span class="co">#&gt; [14,] 0.0108101469 3.546296e-04 0.0042344535 0.9846007700</span></span>
<span><span class="co">#&gt; [15,] 0.0479272686 7.339603e-03 0.7988423691 0.1458907596</span></span>
<span><span class="co">#&gt; [16,] 0.2582285537 1.790023e-03 0.0193994922 0.7205819308</span></span>
<span><span class="co">#&gt; [17,] 0.0139956356 2.992467e-04 0.0028210909 0.9828840268</span></span>
<span><span class="co">#&gt; [18,] 0.9174735098 7.873177e-04 0.0063813311 0.0753578413</span></span>
<span><span class="co">#&gt; [19,] 0.2317978105 1.706749e-03 0.0186406636 0.7478547771</span></span>
<span><span class="co">#&gt; [20,] 0.0036415856 1.752623e-04 0.0012703801 0.9949127720</span></span>
<span><span class="co">#&gt; [21,] 0.1103148479 6.991522e-03 0.1998397863 0.6828538438</span></span>
<span><span class="co">#&gt; [22,] 0.2221577042 1.673234e-03 0.0183261850 0.7578428765</span></span>
<span><span class="co">#&gt; [23,] 0.7877221806 1.462008e-03 0.0132739794 0.1975418321</span></span>
<span><span class="co">#&gt; [24,] 0.0277986593 1.494299e-02 0.9032587618 0.0539995903</span></span>
<span><span class="co">#&gt; [25,] 0.5973096571 1.981387e-03 0.0194190810 0.3812898744</span></span>
<span><span class="co">#&gt; [26,] 0.0008597157 1.149213e-04 0.0003260866 0.9986992764</span></span>
<span><span class="co">#&gt; [27,] 0.0277799331 5.009366e-03 0.8892361213 0.0779745798</span></span>
<span><span class="co">#&gt; [28,] 0.0260730638 1.366797e-02 0.9093202772 0.0509386883</span></span>
<span><span class="co">#&gt; [29,] 0.0001214352 1.060253e-04 0.9996225484 0.0001499911</span></span>
<span><span class="co">#&gt; [30,] 0.7877221806 1.462008e-03 0.0132739794 0.1975418321</span></span>
<span><span class="co">#&gt; [31,] 0.9575967584 8.450343e-04 0.0056378365 0.0359203708</span></span>
<span><span class="co">#&gt; [32,] 0.0738045277 9.352504e-03 0.6663920182 0.2504509498</span></span>
<span><span class="co">#&gt; [33,] 0.9921090594 2.098650e-04 0.0009696709 0.0067114047</span></span>
<span><span class="co">#&gt; [34,] 0.9575967584 8.450343e-04 0.0056378365 0.0359203708</span></span>
<span><span class="co">#&gt; [35,] 0.0001002408 9.996988e-01 0.0001006214 0.0001003223</span></span>
<span><span class="co">#&gt; [36,] 0.0114357248 2.483766e-03 0.9564322241 0.0296482850</span></span>
<span><span class="co">#&gt; [37,] 0.1103148479 6.991522e-03 0.1998397863 0.6828538438</span></span>
<span><span class="co">#&gt; [38,] 0.9996992700 9.997078e-05 0.0001000486 0.0001007107</span></span>
<span><span class="co">#&gt; [39,] 0.9575967584 8.450343e-04 0.0056378365 0.0359203708</span></span>
<span><span class="co">#&gt; [40,] 0.9575967584 8.450343e-04 0.0056378365 0.0359203708</span></span>
<span><span class="co">#&gt; [41,] 0.0036415856 1.752623e-04 0.0012703801 0.9949127720</span></span>
<span><span class="co">#&gt; [42,] 0.0196935294 9.388817e-03 0.9315671947 0.0393504589</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.5078152 0.1310380 0.6253094 0.7107888</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 0.25 0.25 0.25 0.25</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -10976</span></span>
<span><span class="co">#&gt; [1] "output_files /tmp/RtmpYyUiwz/timing_mixed_simple-diagnostic-202411270931-1-88e1e5.csv\n"</span></span>
<span><span class="co">#&gt; init_taus from clustering  0.846922037855411 init_taus from clustering  0.575631127497086 init_taus from clustering  0.716406746962572 init_taus from clustering  0.460516198930884 init_taus from clustering  0.778655945645007</span></span>
<span><span class="co">#&gt; Attempt 1 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.009273 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 92.73 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -11050.963             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -10981.225             0.503            1.000 </span></span>
<span><span class="co">#&gt;      3       -10933.198             0.337            0.006   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  41.5 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;               [,1]         [,2]         [,3]         [,4]         [,5]</span></span>
<span><span class="co">#&gt;  [1,] 0.9611410146 0.0015572686 0.0069607253 0.0008019210 0.0295390705</span></span>
<span><span class="co">#&gt;  [2,] 0.9889258723 0.0005446640 0.0021124114 0.0003164180 0.0081006343</span></span>
<span><span class="co">#&gt;  [3,] 0.7877539658 0.0060697171 0.0315162610 0.0028957119 0.1717643441</span></span>
<span><span class="co">#&gt;  [4,] 0.0176276902 0.0015234418 0.0129208055 0.0006961054 0.9672319571</span></span>
<span><span class="co">#&gt;  [5,] 0.0003465144 0.0003253304 0.9980134892 0.0001672492 0.0011474168</span></span>
<span><span class="co">#&gt;  [6,] 0.0439083222 0.0111849044 0.2289911865 0.0042326087 0.7116829782</span></span>
<span><span class="co">#&gt;  [7,] 0.0052322810 0.0005827869 0.0047588056 0.0002997682 0.9891263582</span></span>
<span><span class="co">#&gt;  [8,] 0.1614563216 0.0071481370 0.0508578634 0.0031788531 0.7773588249</span></span>
<span><span class="co">#&gt;  [9,] 0.0172500024 0.0092195378 0.8648503160 0.0031338748 0.1055462690</span></span>
<span><span class="co">#&gt; [10,] 0.8115276488 0.0146706407 0.0481581625 0.0078919594 0.1177515885</span></span>
<span><span class="co">#&gt; [11,] 0.0291830846 0.0132092397 0.7445146817 0.0045873090 0.2085056851</span></span>
<span><span class="co">#&gt; [12,] 0.0455192979 0.0121279093 0.2626069305 0.0045573829 0.6751884794</span></span>
<span><span class="co">#&gt; [13,] 0.0197683393 0.0335499341 0.8741707158 0.0086522198 0.0638587910</span></span>
<span><span class="co">#&gt; [14,] 0.0020965149 0.0015531092 0.9859832992 0.0005553492 0.0098117276</span></span>
<span><span class="co">#&gt; [15,] 0.0089688726 0.9061021596 0.0400258921 0.0278585421 0.0170445336</span></span>
<span><span class="co">#&gt; [16,] 0.0100887468 0.0016118911 0.0194948538 0.0006984501 0.9681060582</span></span>
<span><span class="co">#&gt; [17,] 0.0416876135 0.0155343505 0.5672419229 0.0055501626 0.3699859504</span></span>
<span><span class="co">#&gt; [18,] 0.4168143270 0.0097552216 0.0598158705 0.0044553341 0.5091592469</span></span>
<span><span class="co">#&gt; [19,] 0.0140417392 0.0023428447 0.0302033544 0.0009821179 0.9524299437</span></span>
<span><span class="co">#&gt; [20,] 0.0079294139 0.0049692324 0.9428417363 0.0016737782 0.0425858391</span></span>
<span><span class="co">#&gt; [21,] 0.0467614736 0.1827733676 0.6136988488 0.0357422170 0.1210240930</span></span>
<span><span class="co">#&gt; [22,] 0.0156228625 0.0026550018 0.0350027184 0.0011024308 0.9456169864</span></span>
<span><span class="co">#&gt; [23,] 0.1614563216 0.0071481370 0.0508578634 0.0031788531 0.7773588249</span></span>
<span><span class="co">#&gt; [24,] 0.0031519757 0.0459952196 0.0074824722 0.9386557876 0.0047145449</span></span>
<span><span class="co">#&gt; [25,] 0.0304071756 0.0023317715 0.0193751908 0.0010416597 0.9468442024</span></span>
<span><span class="co">#&gt; [26,] 0.0138505149 0.0078000469 0.8946434815 0.0026378439 0.0810681128</span></span>
<span><span class="co">#&gt; [27,] 0.0018157530 0.9805087290 0.0069966597 0.0074272118 0.0032516465</span></span>
<span><span class="co">#&gt; [28,] 0.0039358709 0.0602243118 0.0094525122 0.9204684972 0.0059188079</span></span>
<span><span class="co">#&gt; [29,] 0.0090049374 0.8322357805 0.0276359555 0.1161740625 0.0149492642</span></span>
<span><span class="co">#&gt; [30,] 0.1614563216 0.0071481370 0.0508578634 0.0031788531 0.7773588249</span></span>
<span><span class="co">#&gt; [31,] 0.9759042659 0.0013902093 0.0052618373 0.0007499612 0.0166937264</span></span>
<span><span class="co">#&gt; [32,] 0.0226534864 0.7627831012 0.1186446508 0.0504538324 0.0454649292</span></span>
<span><span class="co">#&gt; [33,] 0.9920067618 0.0004215464 0.0015450378 0.0002567866 0.0057698674</span></span>
<span><span class="co">#&gt; [34,] 0.9759042659 0.0013902093 0.0052618373 0.0007499612 0.0166937264</span></span>
<span><span class="co">#&gt; [35,] 0.1095807390 0.2371461096 0.1531180558 0.3705307539 0.1296243417</span></span>
<span><span class="co">#&gt; [36,] 0.0003252731 0.9967746191 0.0009138984 0.0014879710 0.0004982384</span></span>
<span><span class="co">#&gt; [37,] 0.0467614736 0.1827733676 0.6136988488 0.0357422170 0.1210240930</span></span>
<span><span class="co">#&gt; [38,] 0.9263315552 0.0026675672 0.0125697970 0.0013268102 0.0571042703</span></span>
<span><span class="co">#&gt; [39,] 0.9759042659 0.0013902093 0.0052618373 0.0007499612 0.0166937264</span></span>
<span><span class="co">#&gt; [40,] 0.9759042659 0.0013902093 0.0052618373 0.0007499612 0.0166937264</span></span>
<span><span class="co">#&gt; [41,] 0.0079294139 0.0049692324 0.9428417363 0.0016737782 0.0425858391</span></span>
<span><span class="co">#&gt; [42,] 0.0074165300 0.1362098920 0.0185078781 0.8265229097 0.0113427902</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.8469220 0.5756311 0.7164067 0.4605162 0.7786559</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 0.2 0.2 0.2 0.2 0.2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -10933.2</span></span>
<span><span class="co">#&gt; Attempt 2 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.00933 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 93.3 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -11275.635             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -10977.809             0.514            1.000 </span></span>
<span><span class="co">#&gt;      3       -10951.947             0.343            0.027   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  41.6 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;               [,1]         [,2]         [,3]         [,4]         [,5]</span></span>
<span><span class="co">#&gt;  [1,] 0.9611410146 0.0015572686 0.0069607253 0.0008019210 0.0295390705</span></span>
<span><span class="co">#&gt;  [2,] 0.9889258723 0.0005446640 0.0021124114 0.0003164180 0.0081006343</span></span>
<span><span class="co">#&gt;  [3,] 0.7877539658 0.0060697171 0.0315162610 0.0028957119 0.1717643441</span></span>
<span><span class="co">#&gt;  [4,] 0.0176276902 0.0015234418 0.0129208055 0.0006961054 0.9672319571</span></span>
<span><span class="co">#&gt;  [5,] 0.0003465144 0.0003253304 0.9980134892 0.0001672492 0.0011474168</span></span>
<span><span class="co">#&gt;  [6,] 0.0439083222 0.0111849044 0.2289911865 0.0042326087 0.7116829782</span></span>
<span><span class="co">#&gt;  [7,] 0.0052322810 0.0005827869 0.0047588056 0.0002997682 0.9891263582</span></span>
<span><span class="co">#&gt;  [8,] 0.1614563216 0.0071481370 0.0508578634 0.0031788531 0.7773588249</span></span>
<span><span class="co">#&gt;  [9,] 0.0172500024 0.0092195378 0.8648503160 0.0031338748 0.1055462690</span></span>
<span><span class="co">#&gt; [10,] 0.8115276488 0.0146706407 0.0481581625 0.0078919594 0.1177515885</span></span>
<span><span class="co">#&gt; [11,] 0.0291830846 0.0132092397 0.7445146817 0.0045873090 0.2085056851</span></span>
<span><span class="co">#&gt; [12,] 0.0455192979 0.0121279093 0.2626069305 0.0045573829 0.6751884794</span></span>
<span><span class="co">#&gt; [13,] 0.0197683393 0.0335499341 0.8741707158 0.0086522198 0.0638587910</span></span>
<span><span class="co">#&gt; [14,] 0.0020965149 0.0015531092 0.9859832992 0.0005553492 0.0098117276</span></span>
<span><span class="co">#&gt; [15,] 0.0089688726 0.9061021596 0.0400258921 0.0278585421 0.0170445336</span></span>
<span><span class="co">#&gt; [16,] 0.0100887468 0.0016118911 0.0194948538 0.0006984501 0.9681060582</span></span>
<span><span class="co">#&gt; [17,] 0.0416876135 0.0155343505 0.5672419229 0.0055501626 0.3699859504</span></span>
<span><span class="co">#&gt; [18,] 0.4168143270 0.0097552216 0.0598158705 0.0044553341 0.5091592469</span></span>
<span><span class="co">#&gt; [19,] 0.0140417392 0.0023428447 0.0302033544 0.0009821179 0.9524299437</span></span>
<span><span class="co">#&gt; [20,] 0.0079294139 0.0049692324 0.9428417363 0.0016737782 0.0425858391</span></span>
<span><span class="co">#&gt; [21,] 0.0467614736 0.1827733676 0.6136988488 0.0357422170 0.1210240930</span></span>
<span><span class="co">#&gt; [22,] 0.0156228625 0.0026550018 0.0350027184 0.0011024308 0.9456169864</span></span>
<span><span class="co">#&gt; [23,] 0.1614563216 0.0071481370 0.0508578634 0.0031788531 0.7773588249</span></span>
<span><span class="co">#&gt; [24,] 0.0031519757 0.0459952196 0.0074824722 0.9386557876 0.0047145449</span></span>
<span><span class="co">#&gt; [25,] 0.0304071756 0.0023317715 0.0193751908 0.0010416597 0.9468442024</span></span>
<span><span class="co">#&gt; [26,] 0.0138505149 0.0078000469 0.8946434815 0.0026378439 0.0810681128</span></span>
<span><span class="co">#&gt; [27,] 0.0018157530 0.9805087290 0.0069966597 0.0074272118 0.0032516465</span></span>
<span><span class="co">#&gt; [28,] 0.0039358709 0.0602243118 0.0094525122 0.9204684972 0.0059188079</span></span>
<span><span class="co">#&gt; [29,] 0.0090049374 0.8322357805 0.0276359555 0.1161740625 0.0149492642</span></span>
<span><span class="co">#&gt; [30,] 0.1614563216 0.0071481370 0.0508578634 0.0031788531 0.7773588249</span></span>
<span><span class="co">#&gt; [31,] 0.9759042659 0.0013902093 0.0052618373 0.0007499612 0.0166937264</span></span>
<span><span class="co">#&gt; [32,] 0.0226534864 0.7627831012 0.1186446508 0.0504538324 0.0454649292</span></span>
<span><span class="co">#&gt; [33,] 0.9920067618 0.0004215464 0.0015450378 0.0002567866 0.0057698674</span></span>
<span><span class="co">#&gt; [34,] 0.9759042659 0.0013902093 0.0052618373 0.0007499612 0.0166937264</span></span>
<span><span class="co">#&gt; [35,] 0.1095807390 0.2371461096 0.1531180558 0.3705307539 0.1296243417</span></span>
<span><span class="co">#&gt; [36,] 0.0003252731 0.9967746191 0.0009138984 0.0014879710 0.0004982384</span></span>
<span><span class="co">#&gt; [37,] 0.0467614736 0.1827733676 0.6136988488 0.0357422170 0.1210240930</span></span>
<span><span class="co">#&gt; [38,] 0.9263315552 0.0026675672 0.0125697970 0.0013268102 0.0571042703</span></span>
<span><span class="co">#&gt; [39,] 0.9759042659 0.0013902093 0.0052618373 0.0007499612 0.0166937264</span></span>
<span><span class="co">#&gt; [40,] 0.9759042659 0.0013902093 0.0052618373 0.0007499612 0.0166937264</span></span>
<span><span class="co">#&gt; [41,] 0.0079294139 0.0049692324 0.9428417363 0.0016737782 0.0425858391</span></span>
<span><span class="co">#&gt; [42,] 0.0074165300 0.1362098920 0.0185078781 0.8265229097 0.0113427902</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.7554940 0.8800000 0.7231075 0.3975749 0.6059676</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 0.2 0.2 0.2 0.2 0.2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -10951.9</span></span>
<span><span class="co">#&gt; [1] "output_files /tmp/RtmpYyUiwz/timing_mixed_simple-diagnostic-202411270932-1-2f8006.csv\n"</span></span>
<span><span class="co">#&gt; init_taus from clustering  0.784999645698112 init_taus from clustering  0.000235051279729694 init_taus from clustering  0.490150661526823 init_taus from clustering  0.594054683554349 init_taus from clustering  0.849443376180322 init_taus from clustering  0.724222551723491</span></span>
<span><span class="co">#&gt; Attempt 1 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.011034 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 110.34 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -13742.438             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -11202.479             0.613            1.000 </span></span>
<span><span class="co">#&gt;      3       -11073.432             0.413            0.227 </span></span>
<span><span class="co">#&gt;      4       -11023.548             0.311            0.227 </span></span>
<span><span class="co">#&gt;      5       -10995.921             0.249            0.012   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  50.5 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;               [,1]         [,2]         [,3]         [,4]         [,5]</span></span>
<span><span class="co">#&gt;  [1,] 5.588028e-02 0.0003134501 1.343609e-03 2.636433e-03 9.279279e-01</span></span>
<span><span class="co">#&gt;  [2,] 2.051510e-02 0.0001913822 6.245529e-04 1.158167e-03 9.726909e-01</span></span>
<span><span class="co">#&gt;  [3,] 2.528938e-01 0.0007000903 3.738425e-03 7.744867e-03 6.947623e-01</span></span>
<span><span class="co">#&gt;  [4,] 9.978077e-01 0.0001049137 1.349134e-04 1.827964e-04 8.828834e-04</span></span>
<span><span class="co">#&gt;  [5,] 1.906607e-02 0.0002857353 1.985219e-03 6.649905e-03 5.289041e-03</span></span>
<span><span class="co">#&gt;  [6,] 5.101068e-01 0.0008439895 6.109371e-03 1.628446e-02 4.892186e-02</span></span>
<span><span class="co">#&gt;  [7,] 9.977874e-01 0.0001049606 1.357724e-04 1.859394e-04 8.023099e-04</span></span>
<span><span class="co">#&gt;  [8,] 8.769691e-01 0.0004093794 2.161319e-03 4.765688e-03 8.114597e-02</span></span>
<span><span class="co">#&gt;  [9,] 2.422680e-02 0.0002238648 1.231214e-03 3.566085e-03 4.960635e-03</span></span>
<span><span class="co">#&gt; [10,] 1.171570e-01 0.0017001043 8.047599e-03 1.463610e-02 8.117613e-01</span></span>
<span><span class="co">#&gt; [11,] 7.650713e-02 0.0004107803 2.854944e-03 8.270238e-03 1.370766e-02</span></span>
<span><span class="co">#&gt; [12,] 4.683384e-01 0.0008526818 6.220758e-03 1.669527e-02 4.788772e-02</span></span>
<span><span class="co">#&gt; [13,] 8.902851e-02 0.0016539050 1.817736e-02 7.578652e-02 3.075078e-02</span></span>
<span><span class="co">#&gt; [14,] 1.312239e-03 0.0001091676 1.893522e-04 3.934865e-04 3.960558e-04</span></span>
<span><span class="co">#&gt; [15,] 1.144905e-03 0.0001992830 3.058926e-03 9.925040e-01 6.746272e-04</span></span>
<span><span class="co">#&gt; [16,] 8.830679e-01 0.0003939017 2.314621e-03 5.680706e-03 2.843060e-02</span></span>
<span><span class="co">#&gt; [17,] 1.847509e-01 0.0006547589 4.857444e-03 1.371905e-02 2.783556e-02</span></span>
<span><span class="co">#&gt; [18,] 6.348185e-01 0.0007567033 4.292331e-03 9.267563e-03 2.935316e-01</span></span>
<span><span class="co">#&gt; [19,] 8.525695e-01 0.0004570770 2.811184e-03 6.980507e-03 3.295006e-02</span></span>
<span><span class="co">#&gt; [20,] 2.945405e-03 0.0001178557 2.683301e-04 6.333183e-04 7.348332e-04</span></span>
<span><span class="co">#&gt; [21,] 1.139230e-01 0.0036854126 5.118909e-02 3.017945e-01 4.779627e-02</span></span>
<span><span class="co">#&gt; [22,] 8.400734e-01 0.0004814672 3.004774e-03 7.491799e-03 3.458660e-02</span></span>
<span><span class="co">#&gt; [23,] 8.769691e-01 0.0004093794 2.161319e-03 4.765688e-03 8.114597e-02</span></span>
<span><span class="co">#&gt; [24,] 9.296136e-04 0.0004303843 9.904555e-01 6.123149e-03 6.645268e-04</span></span>
<span><span class="co">#&gt; [25,] 9.906913e-01 0.0001256278 2.788719e-04 5.204162e-04 4.476953e-03</span></span>
<span><span class="co">#&gt; [26,] 1.453283e-02 0.0001793674 8.319385e-04 2.366907e-03 3.111764e-03</span></span>
<span><span class="co">#&gt; [27,] 1.522110e-03 0.0002629218 6.131698e-03 9.881183e-01 9.103786e-04</span></span>
<span><span class="co">#&gt; [28,] 5.220301e-04 0.0002634356 9.948102e-01 3.255423e-03 3.863069e-04</span></span>
<span><span class="co">#&gt; [29,] 2.147013e-02 0.0042812152 4.218067e-01 5.006966e-01 1.339620e-02</span></span>
<span><span class="co">#&gt; [30,] 8.769691e-01 0.0004093794 2.161319e-03 4.765688e-03 8.114597e-02</span></span>
<span><span class="co">#&gt; [31,] 1.134448e-02 0.0001796742 5.346273e-04 9.457497e-04 9.835824e-01</span></span>
<span><span class="co">#&gt; [32,] 1.463836e-02 0.0012043657 2.672924e-02 9.142733e-01 7.733391e-03</span></span>
<span><span class="co">#&gt; [33,] 1.616205e-02 0.0001738885 5.230176e-04 9.516542e-04 9.783189e-01</span></span>
<span><span class="co">#&gt; [34,] 1.134448e-02 0.0001796742 5.346273e-04 9.457497e-04 9.835824e-01</span></span>
<span><span class="co">#&gt; [35,] 9.994203e-05 0.9995002852 9.994516e-05 9.994353e-05 9.994174e-05</span></span>
<span><span class="co">#&gt; [36,] 1.008352e-02 0.0014945820 6.888963e-02 8.939315e-01 5.990788e-03</span></span>
<span><span class="co">#&gt; [37,] 1.139230e-01 0.0036854126 5.118909e-02 3.017945e-01 4.779627e-02</span></span>
<span><span class="co">#&gt; [38,] 9.721663e-02 0.0004270775 2.027657e-03 4.065135e-03 8.770978e-01</span></span>
<span><span class="co">#&gt; [39,] 1.134448e-02 0.0001796742 5.346273e-04 9.457497e-04 9.835824e-01</span></span>
<span><span class="co">#&gt; [40,] 1.134448e-02 0.0001796742 5.346273e-04 9.457497e-04 9.835824e-01</span></span>
<span><span class="co">#&gt; [41,] 2.945405e-03 0.0001178557 2.683301e-04 6.333183e-04 7.348332e-04</span></span>
<span><span class="co">#&gt; [42,] 2.520505e-04 0.0001529189 9.976679e-01 1.382363e-03 2.019259e-04</span></span>
<span><span class="co">#&gt;               [,6]</span></span>
<span><span class="co">#&gt;  [1,] 1.189837e-02</span></span>
<span><span class="co">#&gt;  [2,] 4.819857e-03</span></span>
<span><span class="co">#&gt;  [3,] 4.016052e-02</span></span>
<span><span class="co">#&gt;  [4,] 8.867562e-04</span></span>
<span><span class="co">#&gt;  [5,] 9.667240e-01</span></span>
<span><span class="co">#&gt;  [6,] 4.177335e-01</span></span>
<span><span class="co">#&gt;  [7,] 9.835841e-04</span></span>
<span><span class="co">#&gt;  [8,] 3.454852e-02</span></span>
<span><span class="co">#&gt;  [9,] 9.657914e-01</span></span>
<span><span class="co">#&gt; [10,] 4.669792e-02</span></span>
<span><span class="co">#&gt; [11,] 8.982492e-01</span></span>
<span><span class="co">#&gt; [12,] 4.600051e-01</span></span>
<span><span class="co">#&gt; [13,] 7.846029e-01</span></span>
<span><span class="co">#&gt; [14,] 9.975997e-01</span></span>
<span><span class="co">#&gt; [15,] 2.418248e-03</span></span>
<span><span class="co">#&gt; [16,] 8.011226e-02</span></span>
<span><span class="co">#&gt; [17,] 7.681823e-01</span></span>
<span><span class="co">#&gt; [18,] 5.733330e-02</span></span>
<span><span class="co">#&gt; [19,] 1.042317e-01</span></span>
<span><span class="co">#&gt; [20,] 9.953003e-01</span></span>
<span><span class="co">#&gt; [21,] 4.816117e-01</span></span>
<span><span class="co">#&gt; [22,] 1.143620e-01</span></span>
<span><span class="co">#&gt; [23,] 3.454852e-02</span></span>
<span><span class="co">#&gt; [24,] 1.396835e-03</span></span>
<span><span class="co">#&gt; [25,] 3.906851e-03</span></span>
<span><span class="co">#&gt; [26,] 9.789772e-01</span></span>
<span><span class="co">#&gt; [27,] 3.054606e-03</span></span>
<span><span class="co">#&gt; [28,] 7.625721e-04</span></span>
<span><span class="co">#&gt; [29,] 3.834919e-02</span></span>
<span><span class="co">#&gt; [30,] 3.454852e-02</span></span>
<span><span class="co">#&gt; [31,] 3.413080e-03</span></span>
<span><span class="co">#&gt; [32,] 3.542131e-02</span></span>
<span><span class="co">#&gt; [33,] 3.870479e-03</span></span>
<span><span class="co">#&gt; [34,] 3.413080e-03</span></span>
<span><span class="co">#&gt; [35,] 9.994238e-05</span></span>
<span><span class="co">#&gt; [36,] 1.960997e-02</span></span>
<span><span class="co">#&gt; [37,] 4.816117e-01</span></span>
<span><span class="co">#&gt; [38,] 1.916565e-02</span></span>
<span><span class="co">#&gt; [39,] 3.413080e-03</span></span>
<span><span class="co">#&gt; [40,] 3.413080e-03</span></span>
<span><span class="co">#&gt; [41,] 9.953003e-01</span></span>
<span><span class="co">#&gt; [42,] 3.428522e-04</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.7849996457 0.0002350513 0.4901506615 0.5940546836 0.8494433762</span></span>
<span><span class="co">#&gt; [6] 0.7242225517</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -11073.4</span></span>
<span><span class="co">#&gt; Attempt 2 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.010059 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 100.59 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -11426.474             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -11197.379             0.510            1.000 </span></span>
<span><span class="co">#&gt;      3       -11087.234             0.343            0.020   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  22.1 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;               [,1]         [,2]         [,3]         [,4]         [,5]</span></span>
<span><span class="co">#&gt;  [1,] 5.588028e-02 0.0003134501 1.343609e-03 2.636433e-03 9.279279e-01</span></span>
<span><span class="co">#&gt;  [2,] 2.051510e-02 0.0001913822 6.245529e-04 1.158167e-03 9.726909e-01</span></span>
<span><span class="co">#&gt;  [3,] 2.528938e-01 0.0007000903 3.738425e-03 7.744867e-03 6.947623e-01</span></span>
<span><span class="co">#&gt;  [4,] 9.978077e-01 0.0001049137 1.349134e-04 1.827964e-04 8.828834e-04</span></span>
<span><span class="co">#&gt;  [5,] 1.906607e-02 0.0002857353 1.985219e-03 6.649905e-03 5.289041e-03</span></span>
<span><span class="co">#&gt;  [6,] 5.101068e-01 0.0008439895 6.109371e-03 1.628446e-02 4.892186e-02</span></span>
<span><span class="co">#&gt;  [7,] 9.977874e-01 0.0001049606 1.357724e-04 1.859394e-04 8.023099e-04</span></span>
<span><span class="co">#&gt;  [8,] 8.769691e-01 0.0004093794 2.161319e-03 4.765688e-03 8.114597e-02</span></span>
<span><span class="co">#&gt;  [9,] 2.422680e-02 0.0002238648 1.231214e-03 3.566085e-03 4.960635e-03</span></span>
<span><span class="co">#&gt; [10,] 1.171570e-01 0.0017001043 8.047599e-03 1.463610e-02 8.117613e-01</span></span>
<span><span class="co">#&gt; [11,] 7.650713e-02 0.0004107803 2.854944e-03 8.270238e-03 1.370766e-02</span></span>
<span><span class="co">#&gt; [12,] 4.683384e-01 0.0008526818 6.220758e-03 1.669527e-02 4.788772e-02</span></span>
<span><span class="co">#&gt; [13,] 8.902851e-02 0.0016539050 1.817736e-02 7.578652e-02 3.075078e-02</span></span>
<span><span class="co">#&gt; [14,] 1.312239e-03 0.0001091676 1.893522e-04 3.934865e-04 3.960558e-04</span></span>
<span><span class="co">#&gt; [15,] 1.144905e-03 0.0001992830 3.058926e-03 9.925040e-01 6.746272e-04</span></span>
<span><span class="co">#&gt; [16,] 8.830679e-01 0.0003939017 2.314621e-03 5.680706e-03 2.843060e-02</span></span>
<span><span class="co">#&gt; [17,] 1.847509e-01 0.0006547589 4.857444e-03 1.371905e-02 2.783556e-02</span></span>
<span><span class="co">#&gt; [18,] 6.348185e-01 0.0007567033 4.292331e-03 9.267563e-03 2.935316e-01</span></span>
<span><span class="co">#&gt; [19,] 8.525695e-01 0.0004570770 2.811184e-03 6.980507e-03 3.295006e-02</span></span>
<span><span class="co">#&gt; [20,] 2.945405e-03 0.0001178557 2.683301e-04 6.333183e-04 7.348332e-04</span></span>
<span><span class="co">#&gt; [21,] 1.139230e-01 0.0036854126 5.118909e-02 3.017945e-01 4.779627e-02</span></span>
<span><span class="co">#&gt; [22,] 8.400734e-01 0.0004814672 3.004774e-03 7.491799e-03 3.458660e-02</span></span>
<span><span class="co">#&gt; [23,] 8.769691e-01 0.0004093794 2.161319e-03 4.765688e-03 8.114597e-02</span></span>
<span><span class="co">#&gt; [24,] 9.296136e-04 0.0004303843 9.904555e-01 6.123149e-03 6.645268e-04</span></span>
<span><span class="co">#&gt; [25,] 9.906913e-01 0.0001256278 2.788719e-04 5.204162e-04 4.476953e-03</span></span>
<span><span class="co">#&gt; [26,] 1.453283e-02 0.0001793674 8.319385e-04 2.366907e-03 3.111764e-03</span></span>
<span><span class="co">#&gt; [27,] 1.522110e-03 0.0002629218 6.131698e-03 9.881183e-01 9.103786e-04</span></span>
<span><span class="co">#&gt; [28,] 5.220301e-04 0.0002634356 9.948102e-01 3.255423e-03 3.863069e-04</span></span>
<span><span class="co">#&gt; [29,] 2.147013e-02 0.0042812152 4.218067e-01 5.006966e-01 1.339620e-02</span></span>
<span><span class="co">#&gt; [30,] 8.769691e-01 0.0004093794 2.161319e-03 4.765688e-03 8.114597e-02</span></span>
<span><span class="co">#&gt; [31,] 1.134448e-02 0.0001796742 5.346273e-04 9.457497e-04 9.835824e-01</span></span>
<span><span class="co">#&gt; [32,] 1.463836e-02 0.0012043657 2.672924e-02 9.142733e-01 7.733391e-03</span></span>
<span><span class="co">#&gt; [33,] 1.616205e-02 0.0001738885 5.230176e-04 9.516542e-04 9.783189e-01</span></span>
<span><span class="co">#&gt; [34,] 1.134448e-02 0.0001796742 5.346273e-04 9.457497e-04 9.835824e-01</span></span>
<span><span class="co">#&gt; [35,] 9.994203e-05 0.9995002852 9.994516e-05 9.994353e-05 9.994174e-05</span></span>
<span><span class="co">#&gt; [36,] 1.008352e-02 0.0014945820 6.888963e-02 8.939315e-01 5.990788e-03</span></span>
<span><span class="co">#&gt; [37,] 1.139230e-01 0.0036854126 5.118909e-02 3.017945e-01 4.779627e-02</span></span>
<span><span class="co">#&gt; [38,] 9.721663e-02 0.0004270775 2.027657e-03 4.065135e-03 8.770978e-01</span></span>
<span><span class="co">#&gt; [39,] 1.134448e-02 0.0001796742 5.346273e-04 9.457497e-04 9.835824e-01</span></span>
<span><span class="co">#&gt; [40,] 1.134448e-02 0.0001796742 5.346273e-04 9.457497e-04 9.835824e-01</span></span>
<span><span class="co">#&gt; [41,] 2.945405e-03 0.0001178557 2.683301e-04 6.333183e-04 7.348332e-04</span></span>
<span><span class="co">#&gt; [42,] 2.520505e-04 0.0001529189 9.976679e-01 1.382363e-03 2.019259e-04</span></span>
<span><span class="co">#&gt;               [,6]</span></span>
<span><span class="co">#&gt;  [1,] 1.189837e-02</span></span>
<span><span class="co">#&gt;  [2,] 4.819857e-03</span></span>
<span><span class="co">#&gt;  [3,] 4.016052e-02</span></span>
<span><span class="co">#&gt;  [4,] 8.867562e-04</span></span>
<span><span class="co">#&gt;  [5,] 9.667240e-01</span></span>
<span><span class="co">#&gt;  [6,] 4.177335e-01</span></span>
<span><span class="co">#&gt;  [7,] 9.835841e-04</span></span>
<span><span class="co">#&gt;  [8,] 3.454852e-02</span></span>
<span><span class="co">#&gt;  [9,] 9.657914e-01</span></span>
<span><span class="co">#&gt; [10,] 4.669792e-02</span></span>
<span><span class="co">#&gt; [11,] 8.982492e-01</span></span>
<span><span class="co">#&gt; [12,] 4.600051e-01</span></span>
<span><span class="co">#&gt; [13,] 7.846029e-01</span></span>
<span><span class="co">#&gt; [14,] 9.975997e-01</span></span>
<span><span class="co">#&gt; [15,] 2.418248e-03</span></span>
<span><span class="co">#&gt; [16,] 8.011226e-02</span></span>
<span><span class="co">#&gt; [17,] 7.681823e-01</span></span>
<span><span class="co">#&gt; [18,] 5.733330e-02</span></span>
<span><span class="co">#&gt; [19,] 1.042317e-01</span></span>
<span><span class="co">#&gt; [20,] 9.953003e-01</span></span>
<span><span class="co">#&gt; [21,] 4.816117e-01</span></span>
<span><span class="co">#&gt; [22,] 1.143620e-01</span></span>
<span><span class="co">#&gt; [23,] 3.454852e-02</span></span>
<span><span class="co">#&gt; [24,] 1.396835e-03</span></span>
<span><span class="co">#&gt; [25,] 3.906851e-03</span></span>
<span><span class="co">#&gt; [26,] 9.789772e-01</span></span>
<span><span class="co">#&gt; [27,] 3.054606e-03</span></span>
<span><span class="co">#&gt; [28,] 7.625721e-04</span></span>
<span><span class="co">#&gt; [29,] 3.834919e-02</span></span>
<span><span class="co">#&gt; [30,] 3.454852e-02</span></span>
<span><span class="co">#&gt; [31,] 3.413080e-03</span></span>
<span><span class="co">#&gt; [32,] 3.542131e-02</span></span>
<span><span class="co">#&gt; [33,] 3.870479e-03</span></span>
<span><span class="co">#&gt; [34,] 3.413080e-03</span></span>
<span><span class="co">#&gt; [35,] 9.994238e-05</span></span>
<span><span class="co">#&gt; [36,] 1.960997e-02</span></span>
<span><span class="co">#&gt; [37,] 4.816117e-01</span></span>
<span><span class="co">#&gt; [38,] 1.916565e-02</span></span>
<span><span class="co">#&gt; [39,] 3.413080e-03</span></span>
<span><span class="co">#&gt; [40,] 3.413080e-03</span></span>
<span><span class="co">#&gt; [41,] 9.953003e-01</span></span>
<span><span class="co">#&gt; [42,] 3.428522e-04</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.52131387 0.79565966 0.43018417 0.88000000 0.01915634 0.74911746</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -11087.2</span></span>
<span><span class="co">#&gt; [1] "output_files /tmp/RtmpYyUiwz/timing_mixed_simple-diagnostic-202411270934-1-0c5642.csv\n"</span></span>
<span><span class="co">#&gt; init_taus from clustering  0.733321922674837 init_taus from clustering  0.672000532427463 init_taus from clustering  0.850142517825187 init_taus from clustering  0.586603212865031 init_taus from clustering  0.488400959695255 init_taus from clustering  0.789336995435509 init_taus from clustering  0.000212310102096115</span></span>
<span><span class="co">#&gt; Attempt 1 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.011979 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 119.79 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 1] earlier than expected. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -11298.291             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -11074.348             0.510            1.000 </span></span>
<span><span class="co">#&gt;      3       -11021.152             0.342            0.020   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  23.2 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;               [,1]         [,2]         [,3]         [,4]         [,5]</span></span>
<span><span class="co">#&gt;  [1,] 1.521660e-02 6.057874e-03 9.022491e-01 2.684339e-03 1.432609e-03</span></span>
<span><span class="co">#&gt;  [2,] 6.559477e-03 2.727340e-03 9.605426e-01 1.260768e-03 7.045836e-04</span></span>
<span><span class="co">#&gt;  [3,] 4.610475e-02 1.664601e-02 6.240375e-01 6.921290e-03 3.523297e-03</span></span>
<span><span class="co">#&gt;  [4,] 2.420908e-03 6.031509e-04 1.749254e-03 2.653475e-04 1.743754e-04</span></span>
<span><span class="co">#&gt;  [5,] 7.599297e-01 1.532330e-01 1.496859e-02 1.691455e-02 5.473768e-03</span></span>
<span><span class="co">#&gt;  [6,] 6.130894e-01 4.514795e-02 3.617104e-02 1.119383e-02 4.547944e-03</span></span>
<span><span class="co">#&gt;  [7,] 1.458976e-02 3.017971e-03 8.168376e-03 1.033808e-03 5.153186e-04</span></span>
<span><span class="co">#&gt;  [8,] 2.380897e-02 6.535893e-03 4.209480e-02 2.415827e-03 1.186190e-03</span></span>
<span><span class="co">#&gt;  [9,] 9.989352e-01 2.762016e-04 1.465904e-04 1.302512e-04 1.107630e-04</span></span>
<span><span class="co">#&gt; [10,] 4.881014e-02 2.516112e-02 7.849468e-01 1.300181e-02 7.450449e-03</span></span>
<span><span class="co">#&gt; [11,] 9.836328e-01 4.936828e-03 1.770981e-03 1.018300e-03 4.377181e-04</span></span>
<span><span class="co">#&gt; [12,] 6.555118e-01 4.404153e-02 3.316193e-02 1.074175e-02 4.341104e-03</span></span>
<span><span class="co">#&gt; [13,] 2.034929e-01 7.106782e-01 1.330730e-02 2.857321e-02 7.825785e-03</span></span>
<span><span class="co">#&gt; [14,] 9.115034e-01 4.655747e-02 7.183592e-03 6.439626e-03 2.230111e-03</span></span>
<span><span class="co">#&gt; [15,] 9.633642e-03 3.281174e-02 2.807126e-03 9.356698e-01 1.368130e-02</span></span>
<span><span class="co">#&gt; [16,] 1.781917e-01 2.584288e-02 4.026654e-02 7.515803e-03 3.256569e-03</span></span>
<span><span class="co">#&gt; [17,] 9.098140e-01 2.080955e-02 9.726400e-03 4.447673e-03 1.750368e-03</span></span>
<span><span class="co">#&gt; [18,] 5.485452e-02 1.721573e-02 2.171052e-01 6.670242e-03 3.279659e-03</span></span>
<span><span class="co">#&gt; [19,] 2.175784e-01 2.979261e-02 4.303256e-02 8.518496e-03 3.660599e-03</span></span>
<span><span class="co">#&gt; [20,] 9.739304e-01 1.161647e-02 2.434656e-03 1.879301e-03 7.171287e-04</span></span>
<span><span class="co">#&gt; [21,] 6.312299e-03 9.853114e-01 9.191477e-04 4.395256e-03 9.668812e-04</span></span>
<span><span class="co">#&gt; [22,] 2.335164e-01 3.125721e-02 4.387260e-02 8.879653e-03 3.804300e-03</span></span>
<span><span class="co">#&gt; [23,] 2.380897e-02 6.535893e-03 4.209480e-02 2.415827e-03 1.186190e-03</span></span>
<span><span class="co">#&gt; [24,] 8.738368e-04 1.451786e-03 4.611863e-04 4.535820e-03 9.917473e-01</span></span>
<span><span class="co">#&gt; [25,] 1.330447e-04 1.074317e-04 1.274210e-04 1.024371e-04 1.010667e-04</span></span>
<span><span class="co">#&gt; [26,] 9.948683e-01 1.924739e-03 5.429759e-04 4.033769e-04 2.073142e-04</span></span>
<span><span class="co">#&gt; [27,] 1.002165e-04 1.007751e-04 1.000189e-04 9.993984e-01 1.005713e-04</span></span>
<span><span class="co">#&gt; [28,] 4.173766e-04 6.581632e-04 2.471435e-04 1.973270e-03 9.962082e-01</span></span>
<span><span class="co">#&gt; [29,] 2.809580e-02 6.144732e-02 1.079226e-02 5.596360e-01 3.197931e-01</span></span>
<span><span class="co">#&gt; [30,] 2.380897e-02 6.535893e-03 4.209480e-02 2.415827e-03 1.186190e-03</span></span>
<span><span class="co">#&gt; [31,] 3.256157e-03 1.511761e-03 9.832266e-01 7.611662e-04 4.558787e-04</span></span>
<span><span class="co">#&gt; [32,] 4.232289e-02 1.834998e-01 1.075154e-02 7.058151e-01 3.645785e-02</span></span>
<span><span class="co">#&gt; [33,] 5.358264e-03 2.250694e-03 9.681132e-01 1.053314e-03 5.974303e-04</span></span>
<span><span class="co">#&gt; [34,] 3.256157e-03 1.511761e-03 9.832266e-01 7.611662e-04 4.558787e-04</span></span>
<span><span class="co">#&gt; [35,] 9.993033e-05 9.993039e-05 9.993026e-05 9.993049e-05 9.993069e-05</span></span>
<span><span class="co">#&gt; [36,] 8.223454e-03 2.115948e-02 2.839910e-03 9.315256e-01 3.091682e-02</span></span>
<span><span class="co">#&gt; [37,] 6.312299e-03 9.853114e-01 9.191477e-04 4.395256e-03 9.668812e-04</span></span>
<span><span class="co">#&gt; [38,] 2.371959e-02 9.177958e-03 8.385041e-01 3.981690e-03 2.086138e-03</span></span>
<span><span class="co">#&gt; [39,] 3.256157e-03 1.511761e-03 9.832266e-01 7.611662e-04 4.558787e-04</span></span>
<span><span class="co">#&gt; [40,] 3.256157e-03 1.511761e-03 9.832266e-01 7.611662e-04 4.558787e-04</span></span>
<span><span class="co">#&gt; [41,] 9.739304e-01 1.161647e-02 2.434656e-03 1.879301e-03 7.171287e-04</span></span>
<span><span class="co">#&gt; [42,] 5.948908e-04 9.940121e-04 3.235903e-04 3.394755e-03 9.940511e-01</span></span>
<span><span class="co">#&gt;               [,6]         [,7]</span></span>
<span><span class="co">#&gt;  [1,] 7.202850e-02 3.310242e-04</span></span>
<span><span class="co">#&gt;  [2,] 2.799881e-02 2.063709e-04</span></span>
<span><span class="co">#&gt;  [3,] 3.020967e-01 6.704794e-04</span></span>
<span><span class="co">#&gt;  [4,] 9.946763e-01 1.106417e-04</span></span>
<span><span class="co">#&gt;  [5,] 4.884252e-02 6.377901e-04</span></span>
<span><span class="co">#&gt;  [6,] 2.891919e-01 6.578908e-04</span></span>
<span><span class="co">#&gt;  [7,] 9.725159e-01 1.588247e-04</span></span>
<span><span class="co">#&gt;  [8,] 9.236935e-01 2.648287e-04</span></span>
<span><span class="co">#&gt;  [9,] 2.998960e-04 1.011339e-04</span></span>
<span><span class="co">#&gt; [10,] 1.190369e-01 1.592807e-03</span></span>
<span><span class="co">#&gt; [11,] 8.064816e-03 1.385796e-04</span></span>
<span><span class="co">#&gt; [12,] 2.515735e-01 6.284011e-04</span></span>
<span><span class="co">#&gt; [13,] 3.534711e-02 7.754981e-04</span></span>
<span><span class="co">#&gt; [14,] 2.576270e-02 3.230858e-04</span></span>
<span><span class="co">#&gt; [15,] 4.825849e-03 5.704999e-04</span></span>
<span><span class="co">#&gt; [16,] 7.444024e-01 5.241338e-04</span></span>
<span><span class="co">#&gt; [17,] 5.315698e-02 2.950519e-04</span></span>
<span><span class="co">#&gt; [18,] 7.002712e-01 6.034718e-04</span></span>
<span><span class="co">#&gt; [19,] 6.968425e-01 5.748279e-04</span></span>
<span><span class="co">#&gt; [20,] 9.255458e-03 1.665644e-04</span></span>
<span><span class="co">#&gt; [21,] 1.933014e-03 1.619809e-04</span></span>
<span><span class="co">#&gt; [22,] 6.780773e-01 5.925740e-04</span></span>
<span><span class="co">#&gt; [23,] 9.236935e-01 2.648287e-04</span></span>
<span><span class="co">#&gt; [24,] 6.179190e-04 3.121519e-04</span></span>
<span><span class="co">#&gt; [25,] 9.993285e-01 1.000951e-04</span></span>
<span><span class="co">#&gt; [26,] 1.941566e-03 1.117514e-04</span></span>
<span><span class="co">#&gt; [27,] 1.000801e-04 9.994801e-05</span></span>
<span><span class="co">#&gt; [28,] 3.116029e-04 1.842927e-04</span></span>
<span><span class="co">#&gt; [29,] 1.675801e-02 3.477492e-03</span></span>
<span><span class="co">#&gt; [30,] 9.236935e-01 2.648287e-04</span></span>
<span><span class="co">#&gt; [31,] 1.062263e-02 1.658418e-04</span></span>
<span><span class="co">#&gt; [32,] 1.950271e-02 1.650138e-03</span></span>
<span><span class="co">#&gt; [33,] 2.243938e-02 1.877486e-04</span></span>
<span><span class="co">#&gt; [34,] 1.062263e-02 1.658418e-04</span></span>
<span><span class="co">#&gt; [35,] 9.993029e-05 9.994004e-01</span></span>
<span><span class="co">#&gt; [36,] 4.582943e-03 7.518283e-04</span></span>
<span><span class="co">#&gt; [37,] 1.933014e-03 1.619809e-04</span></span>
<span><span class="co">#&gt; [38,] 1.220901e-01 4.404206e-04</span></span>
<span><span class="co">#&gt; [39,] 1.062263e-02 1.658418e-04</span></span>
<span><span class="co">#&gt; [40,] 1.062263e-02 1.658418e-04</span></span>
<span><span class="co">#&gt; [41,] 9.255458e-03 1.665644e-04</span></span>
<span><span class="co">#&gt; [42,] 4.250727e-04 2.165620e-04</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.7333219227 0.6720005324 0.8501425178 0.5866032129 0.4884009597</span></span>
<span><span class="co">#&gt; [6] 0.7893369954 0.0002123101</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -11021.2</span></span>
<span><span class="co">#&gt; Attempt 2 of 2</span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; EXPERIMENTAL ALGORITHM: </span></span>
<span><span class="co">#&gt;   This procedure has not been thoroughly tested and may be unstable </span></span>
<span><span class="co">#&gt;   or buggy. The interface is subject to change. </span></span>
<span><span class="co">#&gt; ------------------------------------------------------------ </span></span>
<span><span class="co">#&gt; Gradient evaluation took 0.011675 seconds </span></span>
<span><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 116.75 seconds. </span></span>
<span><span class="co">#&gt; Adjust your expectations accordingly! </span></span>
<span><span class="co">#&gt; Begin eta adaptation. </span></span>
<span><span class="co">#&gt; Iteration:   1 / 250 [  0%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration:  50 / 250 [ 20%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 100 / 250 [ 40%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 150 / 250 [ 60%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 200 / 250 [ 80%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Iteration: 250 / 250 [100%]  (Adaptation) </span></span>
<span><span class="co">#&gt; Success! Found best value [eta = 0.1]. </span></span>
<span><span class="co">#&gt; Begin stochastic gradient ascent. </span></span>
<span><span class="co">#&gt;   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  </span></span>
<span><span class="co">#&gt;      1       -12539.504             1.000            1.000 </span></span>
<span><span class="co">#&gt;      2       -12542.237             0.500            1.000 </span></span>
<span><span class="co">#&gt;      3       -12170.449             0.344            0.031   MEDIAN ELBO CONVERGED </span></span>
<span><span class="co">#&gt; Drawing a sample of size 1000 from the approximate posterior...  </span></span>
<span><span class="co">#&gt; COMPLETED. </span></span>
<span><span class="co">#&gt; Finished in  36.9 seconds.</span></span>
<span><span class="co">#&gt; [[1]]</span></span>
<span><span class="co">#&gt; [[1]]$w</span></span>
<span><span class="co">#&gt;               [,1]         [,2]         [,3]         [,4]         [,5]</span></span>
<span><span class="co">#&gt;  [1,] 1.521660e-02 6.057874e-03 9.022491e-01 2.684339e-03 1.432609e-03</span></span>
<span><span class="co">#&gt;  [2,] 6.559477e-03 2.727340e-03 9.605426e-01 1.260768e-03 7.045836e-04</span></span>
<span><span class="co">#&gt;  [3,] 4.610475e-02 1.664601e-02 6.240375e-01 6.921290e-03 3.523297e-03</span></span>
<span><span class="co">#&gt;  [4,] 2.420908e-03 6.031509e-04 1.749254e-03 2.653475e-04 1.743754e-04</span></span>
<span><span class="co">#&gt;  [5,] 7.599297e-01 1.532330e-01 1.496859e-02 1.691455e-02 5.473768e-03</span></span>
<span><span class="co">#&gt;  [6,] 6.130894e-01 4.514795e-02 3.617104e-02 1.119383e-02 4.547944e-03</span></span>
<span><span class="co">#&gt;  [7,] 1.458976e-02 3.017971e-03 8.168376e-03 1.033808e-03 5.153186e-04</span></span>
<span><span class="co">#&gt;  [8,] 2.380897e-02 6.535893e-03 4.209480e-02 2.415827e-03 1.186190e-03</span></span>
<span><span class="co">#&gt;  [9,] 9.989352e-01 2.762016e-04 1.465904e-04 1.302512e-04 1.107630e-04</span></span>
<span><span class="co">#&gt; [10,] 4.881014e-02 2.516112e-02 7.849468e-01 1.300181e-02 7.450449e-03</span></span>
<span><span class="co">#&gt; [11,] 9.836328e-01 4.936828e-03 1.770981e-03 1.018300e-03 4.377181e-04</span></span>
<span><span class="co">#&gt; [12,] 6.555118e-01 4.404153e-02 3.316193e-02 1.074175e-02 4.341104e-03</span></span>
<span><span class="co">#&gt; [13,] 2.034929e-01 7.106782e-01 1.330730e-02 2.857321e-02 7.825785e-03</span></span>
<span><span class="co">#&gt; [14,] 9.115034e-01 4.655747e-02 7.183592e-03 6.439626e-03 2.230111e-03</span></span>
<span><span class="co">#&gt; [15,] 9.633642e-03 3.281174e-02 2.807126e-03 9.356698e-01 1.368130e-02</span></span>
<span><span class="co">#&gt; [16,] 1.781917e-01 2.584288e-02 4.026654e-02 7.515803e-03 3.256569e-03</span></span>
<span><span class="co">#&gt; [17,] 9.098140e-01 2.080955e-02 9.726400e-03 4.447673e-03 1.750368e-03</span></span>
<span><span class="co">#&gt; [18,] 5.485452e-02 1.721573e-02 2.171052e-01 6.670242e-03 3.279659e-03</span></span>
<span><span class="co">#&gt; [19,] 2.175784e-01 2.979261e-02 4.303256e-02 8.518496e-03 3.660599e-03</span></span>
<span><span class="co">#&gt; [20,] 9.739304e-01 1.161647e-02 2.434656e-03 1.879301e-03 7.171287e-04</span></span>
<span><span class="co">#&gt; [21,] 6.312299e-03 9.853114e-01 9.191477e-04 4.395256e-03 9.668812e-04</span></span>
<span><span class="co">#&gt; [22,] 2.335164e-01 3.125721e-02 4.387260e-02 8.879653e-03 3.804300e-03</span></span>
<span><span class="co">#&gt; [23,] 2.380897e-02 6.535893e-03 4.209480e-02 2.415827e-03 1.186190e-03</span></span>
<span><span class="co">#&gt; [24,] 8.738368e-04 1.451786e-03 4.611863e-04 4.535820e-03 9.917473e-01</span></span>
<span><span class="co">#&gt; [25,] 1.330447e-04 1.074317e-04 1.274210e-04 1.024371e-04 1.010667e-04</span></span>
<span><span class="co">#&gt; [26,] 9.948683e-01 1.924739e-03 5.429759e-04 4.033769e-04 2.073142e-04</span></span>
<span><span class="co">#&gt; [27,] 1.002165e-04 1.007751e-04 1.000189e-04 9.993984e-01 1.005713e-04</span></span>
<span><span class="co">#&gt; [28,] 4.173766e-04 6.581632e-04 2.471435e-04 1.973270e-03 9.962082e-01</span></span>
<span><span class="co">#&gt; [29,] 2.809580e-02 6.144732e-02 1.079226e-02 5.596360e-01 3.197931e-01</span></span>
<span><span class="co">#&gt; [30,] 2.380897e-02 6.535893e-03 4.209480e-02 2.415827e-03 1.186190e-03</span></span>
<span><span class="co">#&gt; [31,] 3.256157e-03 1.511761e-03 9.832266e-01 7.611662e-04 4.558787e-04</span></span>
<span><span class="co">#&gt; [32,] 4.232289e-02 1.834998e-01 1.075154e-02 7.058151e-01 3.645785e-02</span></span>
<span><span class="co">#&gt; [33,] 5.358264e-03 2.250694e-03 9.681132e-01 1.053314e-03 5.974303e-04</span></span>
<span><span class="co">#&gt; [34,] 3.256157e-03 1.511761e-03 9.832266e-01 7.611662e-04 4.558787e-04</span></span>
<span><span class="co">#&gt; [35,] 9.993033e-05 9.993039e-05 9.993026e-05 9.993049e-05 9.993069e-05</span></span>
<span><span class="co">#&gt; [36,] 8.223454e-03 2.115948e-02 2.839910e-03 9.315256e-01 3.091682e-02</span></span>
<span><span class="co">#&gt; [37,] 6.312299e-03 9.853114e-01 9.191477e-04 4.395256e-03 9.668812e-04</span></span>
<span><span class="co">#&gt; [38,] 2.371959e-02 9.177958e-03 8.385041e-01 3.981690e-03 2.086138e-03</span></span>
<span><span class="co">#&gt; [39,] 3.256157e-03 1.511761e-03 9.832266e-01 7.611662e-04 4.558787e-04</span></span>
<span><span class="co">#&gt; [40,] 3.256157e-03 1.511761e-03 9.832266e-01 7.611662e-04 4.558787e-04</span></span>
<span><span class="co">#&gt; [41,] 9.739304e-01 1.161647e-02 2.434656e-03 1.879301e-03 7.171287e-04</span></span>
<span><span class="co">#&gt; [42,] 5.948908e-04 9.940121e-04 3.235903e-04 3.394755e-03 9.940511e-01</span></span>
<span><span class="co">#&gt;               [,6]         [,7]</span></span>
<span><span class="co">#&gt;  [1,] 7.202850e-02 3.310242e-04</span></span>
<span><span class="co">#&gt;  [2,] 2.799881e-02 2.063709e-04</span></span>
<span><span class="co">#&gt;  [3,] 3.020967e-01 6.704794e-04</span></span>
<span><span class="co">#&gt;  [4,] 9.946763e-01 1.106417e-04</span></span>
<span><span class="co">#&gt;  [5,] 4.884252e-02 6.377901e-04</span></span>
<span><span class="co">#&gt;  [6,] 2.891919e-01 6.578908e-04</span></span>
<span><span class="co">#&gt;  [7,] 9.725159e-01 1.588247e-04</span></span>
<span><span class="co">#&gt;  [8,] 9.236935e-01 2.648287e-04</span></span>
<span><span class="co">#&gt;  [9,] 2.998960e-04 1.011339e-04</span></span>
<span><span class="co">#&gt; [10,] 1.190369e-01 1.592807e-03</span></span>
<span><span class="co">#&gt; [11,] 8.064816e-03 1.385796e-04</span></span>
<span><span class="co">#&gt; [12,] 2.515735e-01 6.284011e-04</span></span>
<span><span class="co">#&gt; [13,] 3.534711e-02 7.754981e-04</span></span>
<span><span class="co">#&gt; [14,] 2.576270e-02 3.230858e-04</span></span>
<span><span class="co">#&gt; [15,] 4.825849e-03 5.704999e-04</span></span>
<span><span class="co">#&gt; [16,] 7.444024e-01 5.241338e-04</span></span>
<span><span class="co">#&gt; [17,] 5.315698e-02 2.950519e-04</span></span>
<span><span class="co">#&gt; [18,] 7.002712e-01 6.034718e-04</span></span>
<span><span class="co">#&gt; [19,] 6.968425e-01 5.748279e-04</span></span>
<span><span class="co">#&gt; [20,] 9.255458e-03 1.665644e-04</span></span>
<span><span class="co">#&gt; [21,] 1.933014e-03 1.619809e-04</span></span>
<span><span class="co">#&gt; [22,] 6.780773e-01 5.925740e-04</span></span>
<span><span class="co">#&gt; [23,] 9.236935e-01 2.648287e-04</span></span>
<span><span class="co">#&gt; [24,] 6.179190e-04 3.121519e-04</span></span>
<span><span class="co">#&gt; [25,] 9.993285e-01 1.000951e-04</span></span>
<span><span class="co">#&gt; [26,] 1.941566e-03 1.117514e-04</span></span>
<span><span class="co">#&gt; [27,] 1.000801e-04 9.994801e-05</span></span>
<span><span class="co">#&gt; [28,] 3.116029e-04 1.842927e-04</span></span>
<span><span class="co">#&gt; [29,] 1.675801e-02 3.477492e-03</span></span>
<span><span class="co">#&gt; [30,] 9.236935e-01 2.648287e-04</span></span>
<span><span class="co">#&gt; [31,] 1.062263e-02 1.658418e-04</span></span>
<span><span class="co">#&gt; [32,] 1.950271e-02 1.650138e-03</span></span>
<span><span class="co">#&gt; [33,] 2.243938e-02 1.877486e-04</span></span>
<span><span class="co">#&gt; [34,] 1.062263e-02 1.658418e-04</span></span>
<span><span class="co">#&gt; [35,] 9.993029e-05 9.994004e-01</span></span>
<span><span class="co">#&gt; [36,] 4.582943e-03 7.518283e-04</span></span>
<span><span class="co">#&gt; [37,] 1.933014e-03 1.619809e-04</span></span>
<span><span class="co">#&gt; [38,] 1.220901e-01 4.404206e-04</span></span>
<span><span class="co">#&gt; [39,] 1.062263e-02 1.658418e-04</span></span>
<span><span class="co">#&gt; [40,] 1.062263e-02 1.658418e-04</span></span>
<span><span class="co">#&gt; [41,] 9.255458e-03 1.665644e-04</span></span>
<span><span class="co">#&gt; [42,] 4.250727e-04 2.165620e-04</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$tau</span></span>
<span><span class="co">#&gt; [1] 0.3965669 0.6194093 0.8699277 0.0700000 0.7828862 0.6621517 0.4771371</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$phi</span></span>
<span><span class="co">#&gt; [1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [[1]]$kappa</span></span>
<span><span class="co">#&gt; [1] 5</span></span>
<span><span class="co">#&gt; ELBO for this run: -12170.4</span></span>
<span><span class="co">#&gt; [1] "output_files /tmp/RtmpYyUiwz/timing_mixed_simple-diagnostic-202411270935-1-439c24.csv\n"</span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="va">data_reduced</span><span class="op">$</span><span class="va">results_timing</span></span>
<span></span>
<span></span>
<span><span class="va">input_data</span> <span class="op">&lt;-</span> <span class="va">results</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">input_data</span></span>
<span><span class="va">draws_and_summary</span> <span class="op">&lt;-</span> <span class="va">results</span><span class="op">$</span><span class="va">draws_and_summary</span></span>
<span><span class="va">log_lik_matrix_list</span> <span class="op">&lt;-</span> <span class="va">results</span><span class="op">$</span><span class="va">log_lik_matrix_list</span></span>
<span><span class="va">elbo_iterations</span> <span class="op">&lt;-</span> <span class="va">results</span><span class="op">$</span><span class="va">elbo_iterations</span></span>
<span></span>
<span><span class="va">results_model_selection</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/model_selection_h.html">model_selection_h</a></span><span class="op">(</span><span class="va">input_data</span>, <span class="va">draws_and_summary</span>, <span class="va">log_lik_matrix_list</span>, <span class="va">elbo_iterations</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.</span></span>
<span><span class="co">#&gt; [1] "entropy per segment: "</span></span>
<span><span class="co">#&gt; [1] -0.003462998</span></span>
<span><span class="co">#&gt; [1] "entropy per segment normalized: "</span></span>
<span><span class="co">#&gt; [1] -9.999995e-07</span></span>
<span><span class="co">#&gt; [1] "entropy per segment: "</span></span>
<span><span class="co">#&gt; [1] 153.3267</span></span>
<span><span class="co">#&gt; [1] "entropy per segment normalized: "</span></span>
<span><span class="co">#&gt; [1] 0.0442757</span></span>
<span><span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.</span></span>
<span><span class="co">#&gt; [1] "entropy per segment: "</span></span>
<span><span class="co">#&gt; [1] 148.632</span></span>
<span><span class="co">#&gt; [1] "entropy per segment normalized: "</span></span>
<span><span class="co">#&gt; [1] 0.04292002</span></span>
<span><span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.</span></span>
<span><span class="co">#&gt; [1] "entropy per segment: "</span></span>
<span><span class="co">#&gt; [1] 14.57779</span></span>
<span><span class="co">#&gt; [1] "entropy per segment normalized: "</span></span>
<span><span class="co">#&gt; [1] 0.004209585</span></span>
<span><span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.</span></span>
<span><span class="co">#&gt; [1] "entropy per segment: "</span></span>
<span><span class="co">#&gt; [1] 414.8372</span></span>
<span><span class="co">#&gt; [1] "entropy per segment normalized: "</span></span>
<span><span class="co">#&gt; [1] 0.1197913</span></span>
<span><span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.</span></span>
<span><span class="co">#&gt; [1] "entropy per segment: "</span></span>
<span><span class="co">#&gt; [1] 1200.246</span></span>
<span><span class="co">#&gt; [1] "entropy per segment normalized: "</span></span>
<span><span class="co">#&gt; [1] 0.3465915</span></span>
<span><span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details.</span></span>
<span><span class="co">#&gt; [1] "entropy per segment: "</span></span>
<span><span class="co">#&gt; [1] 451.0137</span></span>
<span><span class="co">#&gt; [1] "entropy per segment normalized: "</span></span>
<span><span class="co">#&gt; [1] 0.1302379</span></span>
<span></span>
<span><span class="va">best_K</span> <span class="op">&lt;-</span> <span class="va">results_model_selection</span><span class="op">$</span><span class="va">best_K</span></span>
<span><span class="va">model_selection_tibble</span> <span class="op">&lt;-</span> <span class="va">results_model_selection</span><span class="op">$</span><span class="va">model_selection_tibble</span></span>
<span><span class="va">entropy</span> <span class="op">&lt;-</span> <span class="va">results_model_selection</span><span class="op">$</span><span class="va">entropy_list</span></span>
<span></span>
<span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/plot_inference_h.html">plot_inference_h</a></span><span class="op">(</span><span class="va">results</span>, <span class="va">best_K</span><span class="op">)</span></span>
<span><span class="va">p</span></span></code></pre></div>
<p><img src="tickTack_files/figure-html/real%20data-1.png" width="700"></p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by First Last.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
